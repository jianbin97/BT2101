{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3. Data pre-processing: This involves transforming raw data into an understandable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "# visual libraries\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import pylab as pl\n",
    "plt.style.use('ggplot')\n",
    "# sklearn libraries\n",
    "import sklearn \n",
    "plt.style.use('ggplot')\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Dataset\n",
    "data = pd.read_csv('card.csv', sep=',', skiprows=range(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are any duplicate IDs\n",
    "duplicate_column_df = data[data[\"ID\"].duplicated()] #no duplicate IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set ID as index\n",
    "data.set_index('ID', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with BILL_AMTs and PAY_AMTs = 0 \n",
    "indexNames = data[(data['BILL_AMT1'] == 0 ) & (data['BILL_AMT2'] == 0 ) & (data['BILL_AMT3'] == 0 )& \n",
    "                 (data['BILL_AMT4'] == 0 ) & (data['BILL_AMT5'] == 0) & (data['BILL_AMT6'] == 0) ].index\n",
    "data = data.drop(indexNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there are irrelevant data in Marriage (categorical data)\n",
    "data[\"MARRIAGE\"].unique() # 0 is irrelevant datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 5, 4, 6, 0], dtype=int64)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there are irrelevant in Education (categorical data)\n",
    "data[\"EDUCATION\"].unique() # 6 and 0 are  irrelevant datas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    13735\n",
       "1    10158\n",
       "3     4785\n",
       "5      273\n",
       "4      120\n",
       "6       49\n",
       "0       14\n",
       "Name: EDUCATION, dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"EDUCATION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, -1,  0, -2,  1,  3,  4,  8,  7,  5,  6], dtype=int64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there are irrelevant in PAY_0 (categorical data)\n",
    "data[\"PAY_0\"].unique() #-2 and 0 are irrelevant datas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2,  0, -1,  2,  3,  5,  4,  7,  8,  6], dtype=int64)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there are irrelevant in PAY_0 to PAY_5 (categorical data)\n",
    "data[\"PAY_0\"].unique() \n",
    "data[\"PAY_2\"].unique()\n",
    "data[\"PAY_3\"].unique()\n",
    "data[\"PAY_4\"].unique()\n",
    "data[\"PAY_5\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows which values are not justified in the data description (Marriage == 0, PAY == 0 & -2, EDUCATION == 0 & 6)\n",
    "data.drop(data[data[\"MARRIAGE\"] == 0].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_0\"] == 0].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_2\"] == 0].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_3\"] == 0].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_4\"] == 0].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_5\"] == 0].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_6\"] == 0].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_0\"] == -2].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_2\"] == -2].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_3\"] == -2].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_4\"] == -2].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_5\"] == -2].index, inplace=True)\n",
    "data.drop(data[data[\"PAY_6\"] == -2].index, inplace=True)\n",
    "data.drop(data[data[\"EDUCATION\"] == 0].index, inplace=True)\n",
    "data.drop(data[data[\"EDUCATION\"] == 5].index, inplace=True)\n",
    "data.drop(data[data[\"EDUCATION\"] == 6].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL                     0\n",
       "SEX                           0\n",
       "EDUCATION                     0\n",
       "MARRIAGE                      0\n",
       "AGE                           0\n",
       "PAY_0                         0\n",
       "PAY_2                         0\n",
       "PAY_3                         0\n",
       "PAY_4                         0\n",
       "PAY_5                         0\n",
       "PAY_6                         0\n",
       "BILL_AMT1                     0\n",
       "BILL_AMT2                     0\n",
       "BILL_AMT3                     0\n",
       "BILL_AMT4                     0\n",
       "BILL_AMT5                     0\n",
       "BILL_AMT6                     0\n",
       "PAY_AMT1                      0\n",
       "PAY_AMT2                      0\n",
       "PAY_AMT3                      0\n",
       "PAY_AMT4                      0\n",
       "PAY_AMT5                      0\n",
       "PAY_AMT6                      0\n",
       "default payment next month    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Checking for missing values\n",
    "data.isna().sum() #no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the data column for better understanding of the dataset\n",
    "data.rename(columns = {'PAY_0' : 'STATUS_SEP'}, inplace = True)\n",
    "data.rename(columns = {'PAY_2' : 'STATUS_AUG'}, inplace = True)\n",
    "data.rename(columns = {'PAY_3' : 'STATUS_JUL'}, inplace = True)\n",
    "data.rename(columns = {'PAY_4' : 'STATUS_JUN'}, inplace = True)\n",
    "data.rename(columns = {'PAY_5' : 'STATUS_MAY'}, inplace = True)\n",
    "data.rename(columns = {'PAY_6' : 'STATUS_APR'}, inplace = True)\n",
    "data.rename(columns = {'BILL_AMT1' : 'BILL_SEP'}, inplace = True)\n",
    "data.rename(columns = {'BILL_AMT2' : 'BILL_AUG'}, inplace = True)\n",
    "data.rename(columns = {'BILL_AMT3' : 'BILL_JUL'}, inplace = True)\n",
    "data.rename(columns = {'BILL_AMT4' : 'BILL_JUN'}, inplace = True)\n",
    "data.rename(columns = {'BILL_AMT5' : 'BILL_MAY'}, inplace = True)\n",
    "data.rename(columns = {'BILL_AMT6' : 'BILL_APR'}, inplace = True)\n",
    "data.rename(columns = {'PAY_AMT1' : 'PAY_SEP'}, inplace = True)\n",
    "data.rename(columns = {'PAY_AMT2' : 'PAY_AUG'}, inplace = True)\n",
    "data.rename(columns = {'PAY_AMT3' : 'PAY_JUL'}, inplace = True)\n",
    "data.rename(columns = {'PAY_AMT4' : 'PAY_JUN'}, inplace = True)\n",
    "data.rename(columns = {'PAY_AMT5' : 'PAY_MAY'}, inplace = True)\n",
    "data.rename(columns = {'PAY_AMT6' : 'PAY_APR'}, inplace = True)\n",
    "data.rename(columns = {'default payment next month' : 'default'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>STATUS_SEP</th>\n",
       "      <th>STATUS_AUG</th>\n",
       "      <th>STATUS_JUL</th>\n",
       "      <th>STATUS_JUN</th>\n",
       "      <th>STATUS_MAY</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_JUN</th>\n",
       "      <th>BILL_MAY</th>\n",
       "      <th>BILL_APR</th>\n",
       "      <th>PAY_SEP</th>\n",
       "      <th>PAY_AUG</th>\n",
       "      <th>PAY_JUL</th>\n",
       "      <th>PAY_JUN</th>\n",
       "      <th>PAY_MAY</th>\n",
       "      <th>PAY_APR</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>260000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8517</td>\n",
       "      <td>22287</td>\n",
       "      <td>13668</td>\n",
       "      <td>21818</td>\n",
       "      <td>9966</td>\n",
       "      <td>8583</td>\n",
       "      <td>22301</td>\n",
       "      <td>0</td>\n",
       "      <td>3640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>2040</td>\n",
       "      <td>30430</td>\n",
       "      <td>257</td>\n",
       "      <td>3415</td>\n",
       "      <td>3421</td>\n",
       "      <td>2044</td>\n",
       "      <td>30430</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>230000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>15339</td>\n",
       "      <td>14307</td>\n",
       "      <td>36923</td>\n",
       "      <td>17270</td>\n",
       "      <td>13281</td>\n",
       "      <td>15339</td>\n",
       "      <td>14307</td>\n",
       "      <td>37292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>380000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>32018</td>\n",
       "      <td>11849</td>\n",
       "      <td>11873</td>\n",
       "      <td>21540</td>\n",
       "      <td>15138</td>\n",
       "      <td>24677</td>\n",
       "      <td>11851</td>\n",
       "      <td>11875</td>\n",
       "      <td>8251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  STATUS_SEP  STATUS_AUG  \\\n",
       "ID                                                                     \n",
       "12     260000    2          1         2   51          -1          -1   \n",
       "22     120000    2          2         1   39          -1          -1   \n",
       "29      50000    2          3         1   47          -1          -1   \n",
       "31     230000    2          1         2   27          -1          -1   \n",
       "49     380000    1          2         2   32          -1          -1   \n",
       "\n",
       "    STATUS_JUL  STATUS_JUN  STATUS_MAY  ...  BILL_JUN  BILL_MAY  BILL_APR  \\\n",
       "ID                                      ...                                 \n",
       "12          -1          -1          -1  ...      8517     22287     13668   \n",
       "22          -1          -1          -1  ...         0       632       316   \n",
       "29          -1          -1          -1  ...      2040     30430       257   \n",
       "31          -1          -1          -1  ...     15339     14307     36923   \n",
       "49          -1          -1          -1  ...     32018     11849     11873   \n",
       "\n",
       "    PAY_SEP  PAY_AUG  PAY_JUL  PAY_JUN  PAY_MAY  PAY_APR  default  \n",
       "ID                                                                 \n",
       "12    21818     9966     8583    22301        0     3640        0  \n",
       "22      316      316        0      632      316        0        1  \n",
       "29     3415     3421     2044    30430      257        0        0  \n",
       "31    17270    13281    15339    14307    37292        0        0  \n",
       "49    21540    15138    24677    11851    11875     8251        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Type of data \n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4030 entries, 12 to 29995\n",
      "Data columns (total 24 columns):\n",
      "LIMIT_BAL     4030 non-null int64\n",
      "SEX           4030 non-null int64\n",
      "EDUCATION     4030 non-null int64\n",
      "MARRIAGE      4030 non-null int64\n",
      "AGE           4030 non-null int64\n",
      "STATUS_SEP    4030 non-null int64\n",
      "STATUS_AUG    4030 non-null int64\n",
      "STATUS_JUL    4030 non-null int64\n",
      "STATUS_JUN    4030 non-null int64\n",
      "STATUS_MAY    4030 non-null int64\n",
      "STATUS_APR    4030 non-null int64\n",
      "BILL_SEP      4030 non-null int64\n",
      "BILL_AUG      4030 non-null int64\n",
      "BILL_JUL      4030 non-null int64\n",
      "BILL_JUN      4030 non-null int64\n",
      "BILL_MAY      4030 non-null int64\n",
      "BILL_APR      4030 non-null int64\n",
      "PAY_SEP       4030 non-null int64\n",
      "PAY_AUG       4030 non-null int64\n",
      "PAY_JUL       4030 non-null int64\n",
      "PAY_JUN       4030 non-null int64\n",
      "PAY_MAY       4030 non-null int64\n",
      "PAY_APR       4030 non-null int64\n",
      "default       4030 non-null int64\n",
      "dtypes: int64(24)\n",
      "memory usage: 787.1 KB\n"
     ]
    }
   ],
   "source": [
    "#Information about the data \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have identified SEX and MARRIAGE to be nominal discrete attributes, hence,\n",
    "#we will perform data encoding on these 2 attributes. \n",
    "\n",
    "#Renaming variables to their categorical attribute\n",
    "data['SEX'].replace(1,'MALE', inplace=True)\n",
    "data['SEX'].replace(2,'FEMALE', inplace=True)\n",
    "data['MARRIAGE'].replace(1,'MARRIED',inplace=True)\n",
    "data['MARRIAGE'].replace(2,'SINGLE',inplace=True)\n",
    "data['MARRIAGE'].replace(3,'OTHERS',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>STATUS_SEP</th>\n",
       "      <th>STATUS_AUG</th>\n",
       "      <th>STATUS_JUL</th>\n",
       "      <th>STATUS_JUN</th>\n",
       "      <th>STATUS_MAY</th>\n",
       "      <th>STATUS_APR</th>\n",
       "      <th>BILL_SEP</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_JUL</th>\n",
       "      <th>PAY_JUN</th>\n",
       "      <th>PAY_MAY</th>\n",
       "      <th>PAY_APR</th>\n",
       "      <th>SEX_FEMALE</th>\n",
       "      <th>SEX_MALE</th>\n",
       "      <th>MARRIAGE_MARRIED</th>\n",
       "      <th>MARRIAGE_OTHERS</th>\n",
       "      <th>MARRIAGE_SINGLE</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>260000</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>12261</td>\n",
       "      <td>...</td>\n",
       "      <td>8583</td>\n",
       "      <td>22301</td>\n",
       "      <td>0</td>\n",
       "      <td>3640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>50000</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>650</td>\n",
       "      <td>...</td>\n",
       "      <td>2044</td>\n",
       "      <td>30430</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>230000</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>16646</td>\n",
       "      <td>...</td>\n",
       "      <td>15339</td>\n",
       "      <td>14307</td>\n",
       "      <td>37292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>380000</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>22401</td>\n",
       "      <td>...</td>\n",
       "      <td>24677</td>\n",
       "      <td>11851</td>\n",
       "      <td>11875</td>\n",
       "      <td>8251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LIMIT_BAL  EDUCATION  AGE  STATUS_SEP  STATUS_AUG  STATUS_JUL  STATUS_JUN  \\\n",
       "ID                                                                              \n",
       "12     260000          1   51          -1          -1          -1          -1   \n",
       "22     120000          2   39          -1          -1          -1          -1   \n",
       "29      50000          3   47          -1          -1          -1          -1   \n",
       "31     230000          1   27          -1          -1          -1          -1   \n",
       "49     380000          2   32          -1          -1          -1          -1   \n",
       "\n",
       "    STATUS_MAY  STATUS_APR  BILL_SEP  ...  PAY_JUL  PAY_JUN  PAY_MAY  PAY_APR  \\\n",
       "ID                                    ...                                       \n",
       "12          -1           2     12261  ...     8583    22301        0     3640   \n",
       "22          -1          -1       316  ...        0      632      316        0   \n",
       "29          -1          -1       650  ...     2044    30430      257        0   \n",
       "31          -1          -1     16646  ...    15339    14307    37292        0   \n",
       "49          -1          -1     22401  ...    24677    11851    11875     8251   \n",
       "\n",
       "    SEX_FEMALE  SEX_MALE  MARRIAGE_MARRIED  MARRIAGE_OTHERS  MARRIAGE_SINGLE  \\\n",
       "ID                                                                             \n",
       "12           1         0                 0                0                1   \n",
       "22           1         0                 1                0                0   \n",
       "29           1         0                 1                0                0   \n",
       "31           1         0                 0                0                1   \n",
       "49           0         1                 0                0                1   \n",
       "\n",
       "    default  \n",
       "ID           \n",
       "12        0  \n",
       "22        1  \n",
       "29        0  \n",
       "31        0  \n",
       "49        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method to encoded SEX and MARRIAGE columns\n",
    "dummies = pd.get_dummies(data=data, columns=['SEX', 'MARRIAGE'])\n",
    "data = dummies\n",
    "cols_at_end = ['default']\n",
    "data = data[[c for c in data if c not in cols_at_end] + [c for c in cols_at_end if c in data]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huang\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6786: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#Reorder Education Ranking \n",
    "#1 = Graduate School\n",
    "#2 = High School\n",
    "#3 = University \n",
    "#4 = Others (Assume Masters )\n",
    "\n",
    "data['EDUCATION'].replace(2,4, inplace=True)\n",
    "data['EDUCATION'].replace(3,2, inplace=True)\n",
    "data['EDUCATION'].replace(4,3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>STATUS_SEP</th>\n",
       "      <th>STATUS_AUG</th>\n",
       "      <th>STATUS_JUL</th>\n",
       "      <th>STATUS_JUN</th>\n",
       "      <th>STATUS_MAY</th>\n",
       "      <th>STATUS_APR</th>\n",
       "      <th>BILL_SEP</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_JUL</th>\n",
       "      <th>PAY_JUN</th>\n",
       "      <th>PAY_MAY</th>\n",
       "      <th>PAY_APR</th>\n",
       "      <th>SEX_FEMALE</th>\n",
       "      <th>SEX_MALE</th>\n",
       "      <th>MARRIAGE_MARRIED</th>\n",
       "      <th>MARRIAGE_OTHERS</th>\n",
       "      <th>MARRIAGE_SINGLE</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>260000</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>12261</td>\n",
       "      <td>...</td>\n",
       "      <td>8583</td>\n",
       "      <td>22301</td>\n",
       "      <td>0</td>\n",
       "      <td>3640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>120000</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>650</td>\n",
       "      <td>...</td>\n",
       "      <td>2044</td>\n",
       "      <td>30430</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>230000</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>16646</td>\n",
       "      <td>...</td>\n",
       "      <td>15339</td>\n",
       "      <td>14307</td>\n",
       "      <td>37292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>380000</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>22401</td>\n",
       "      <td>...</td>\n",
       "      <td>24677</td>\n",
       "      <td>11851</td>\n",
       "      <td>11875</td>\n",
       "      <td>8251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LIMIT_BAL  EDUCATION  AGE  STATUS_SEP  STATUS_AUG  STATUS_JUL  STATUS_JUN  \\\n",
       "ID                                                                              \n",
       "12     260000          1   51          -1          -1          -1          -1   \n",
       "22     120000          3   39          -1          -1          -1          -1   \n",
       "29      50000          2   47          -1          -1          -1          -1   \n",
       "31     230000          1   27          -1          -1          -1          -1   \n",
       "49     380000          3   32          -1          -1          -1          -1   \n",
       "\n",
       "    STATUS_MAY  STATUS_APR  BILL_SEP  ...  PAY_JUL  PAY_JUN  PAY_MAY  PAY_APR  \\\n",
       "ID                                    ...                                       \n",
       "12          -1           2     12261  ...     8583    22301        0     3640   \n",
       "22          -1          -1       316  ...        0      632      316        0   \n",
       "29          -1          -1       650  ...     2044    30430      257        0   \n",
       "31          -1          -1     16646  ...    15339    14307    37292        0   \n",
       "49          -1          -1     22401  ...    24677    11851    11875     8251   \n",
       "\n",
       "    SEX_FEMALE  SEX_MALE  MARRIAGE_MARRIED  MARRIAGE_OTHERS  MARRIAGE_SINGLE  \\\n",
       "ID                                                                             \n",
       "12           1         0                 0                0                1   \n",
       "22           1         0                 1                0                0   \n",
       "29           1         0                 1                0                0   \n",
       "31           1         0                 0                0                1   \n",
       "49           0         1                 0                0                1   \n",
       "\n",
       "    default  \n",
       "ID           \n",
       "12        0  \n",
       "22        1  \n",
       "29        0  \n",
       "31        0  \n",
       "49        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.216362495725253,\n",
       " 0.0001629474490475851,\n",
       " 1,\n",
       " array([[1535.15880893,  849.84119107],\n",
       "        [1058.84119107,  586.15880893]]))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for MALE and Default\n",
    "chi2_contingency(pd.crosstab(data.SEX_MALE, data.default))\n",
    "# Since P-value is < 0.05, MALE and default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.216362495725253,\n",
       " 0.0001629474490475851,\n",
       " 1,\n",
       " array([[1058.84119107,  586.15880893],\n",
       "        [1535.15880893,  849.84119107]]))"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for FEMALE and Default\n",
    "chi2_contingency(pd.crosstab(data.SEX_FEMALE, data.default))\n",
    "# Since P-value is < 0.05, FEMALE and default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68.43577734733543,\n",
       " 1.3783508126893269e-15,\n",
       " 2,\n",
       " array([[1083.30074442,  599.69925558],\n",
       "        [ 401.6516129 ,  222.3483871 ],\n",
       "        [1109.04764268,  613.95235732]]))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for Education and Default\n",
    "chi2_contingency(pd.crosstab(data.EDUCATION, data.default))\n",
    "# Since P-value is < 0.05, Education and Default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17494728950595756,\n",
       " 0.6757519089000386,\n",
       " 1,\n",
       " array([[1358.14888337,  751.85111663],\n",
       "        [1235.85111663,  684.14888337]]))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for SINGLE and Default\n",
    "chi2_contingency(pd.crosstab(data.MARRIAGE_SINGLE, data.default))\n",
    "# Since P-value is > 0.05, SINGLE and Default are independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5468405918800932,\n",
       " 0.4596115078241867,\n",
       " 1,\n",
       " array([[1257.73598015,  696.26401985],\n",
       "        [1336.26401985,  739.73598015]]))"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for MARRIED and Default\n",
    "chi2_contingency(pd.crosstab(data.MARRIAGE_MARRIED, data.default))\n",
    "# Since P-value is > 0.05, MARRIED and Default are independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4865574152284675,\n",
       " 0.11482263717182488,\n",
       " 1,\n",
       " array([[2572.11513648, 1423.88486352],\n",
       "        [  21.88486352,   12.11513648]]))"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for MARRIED and Default\n",
    "chi2_contingency(pd.crosstab(data.MARRIAGE_OTHERS, data.default))\n",
    "# Since P-value is > 0.05, MARRIED and Default are independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>STATUS_SEP</th>\n",
       "      <th>STATUS_AUG</th>\n",
       "      <th>STATUS_JUL</th>\n",
       "      <th>STATUS_JUN</th>\n",
       "      <th>STATUS_MAY</th>\n",
       "      <th>STATUS_APR</th>\n",
       "      <th>BILL_SEP</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_JUL</th>\n",
       "      <th>PAY_JUN</th>\n",
       "      <th>PAY_MAY</th>\n",
       "      <th>PAY_APR</th>\n",
       "      <th>SEX_FEMALE</th>\n",
       "      <th>SEX_MALE</th>\n",
       "      <th>MARRIAGE_MARRIED</th>\n",
       "      <th>MARRIAGE_OTHERS</th>\n",
       "      <th>MARRIAGE_SINGLE</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>260000</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12261</td>\n",
       "      <td>...</td>\n",
       "      <td>8583</td>\n",
       "      <td>22301</td>\n",
       "      <td>0</td>\n",
       "      <td>3640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>120000</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>650</td>\n",
       "      <td>...</td>\n",
       "      <td>2044</td>\n",
       "      <td>30430</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>230000</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16646</td>\n",
       "      <td>...</td>\n",
       "      <td>15339</td>\n",
       "      <td>14307</td>\n",
       "      <td>37292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>380000</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22401</td>\n",
       "      <td>...</td>\n",
       "      <td>24677</td>\n",
       "      <td>11851</td>\n",
       "      <td>11875</td>\n",
       "      <td>8251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LIMIT_BAL  EDUCATION  AGE  STATUS_SEP  STATUS_AUG  STATUS_JUL  STATUS_JUN  \\\n",
       "ID                                                                              \n",
       "12     260000          1   51           0           0           0           0   \n",
       "22     120000          3   39           0           0           0           0   \n",
       "29      50000          2   47           0           0           0           0   \n",
       "31     230000          1   27           0           0           0           0   \n",
       "49     380000          3   32           0           0           0           0   \n",
       "\n",
       "    STATUS_MAY  STATUS_APR  BILL_SEP  ...  PAY_JUL  PAY_JUN  PAY_MAY  PAY_APR  \\\n",
       "ID                                    ...                                       \n",
       "12           0           2     12261  ...     8583    22301        0     3640   \n",
       "22           0           0       316  ...        0      632      316        0   \n",
       "29           0           0       650  ...     2044    30430      257        0   \n",
       "31           0           0     16646  ...    15339    14307    37292        0   \n",
       "49           0           0     22401  ...    24677    11851    11875     8251   \n",
       "\n",
       "    SEX_FEMALE  SEX_MALE  MARRIAGE_MARRIED  MARRIAGE_OTHERS  MARRIAGE_SINGLE  \\\n",
       "ID                                                                             \n",
       "12           1         0                 0                0                1   \n",
       "22           1         0                 1                0                0   \n",
       "29           1         0                 1                0                0   \n",
       "31           1         0                 0                0                1   \n",
       "49           0         1                 0                0                1   \n",
       "\n",
       "    default  \n",
       "ID           \n",
       "12        0  \n",
       "22        1  \n",
       "29        0  \n",
       "31        0  \n",
       "49        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since Chi Square test can only be used with positive variables, we will change the -1 values for \n",
    "#STATUS_SEP to STATUS_APR to 10 (paid on time)\n",
    "\n",
    "data[data.columns[3:9]] = data[data.columns[3:9]].replace(-1,0) #replace -1 values with 0 \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1071.9511104410667,\n",
       " 4.370093747720005e-226,\n",
       " 8,\n",
       " array([[1.52550372e+03, 8.44496278e+02],\n",
       "        [4.08088337e+02, 2.25911663e+02],\n",
       "        [5.09144913e+02, 2.81855087e+02],\n",
       "        [1.04274938e+02, 5.77250620e+01],\n",
       "        [2.18848635e+01, 1.21151365e+01],\n",
       "        [5.14937965e+00, 2.85062035e+00],\n",
       "        [1.93101737e+00, 1.06898263e+00],\n",
       "        [5.79305211e+00, 3.20694789e+00],\n",
       "        [1.22297767e+01, 6.77022333e+00]]))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for STATUS_SEP and default\n",
    "chi2_contingency(pd.crosstab(data.STATUS_SEP, data.default))\n",
    "# Since P-value is < 0.05, STATUS_SEP and Default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1032.9932692855323,\n",
       " 1.1270361945654215e-217,\n",
       " 8,\n",
       " array([[1.57249181e+03, 8.70508189e+02],\n",
       "        [2.57468983e+00, 1.42531017e+00],\n",
       "        [8.63808437e+02, 4.78191563e+02],\n",
       "        [9.01141439e+01, 4.98858561e+01],\n",
       "        [3.73330025e+01, 2.06669975e+01],\n",
       "        [6.43672457e+00, 3.56327543e+00],\n",
       "        [7.72406948e+00, 4.27593052e+00],\n",
       "        [1.28734491e+01, 7.12655087e+00],\n",
       "        [6.43672457e-01, 3.56327543e-01]]))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for STATUS_AUG and default\n",
    "chi2_contingency(pd.crosstab(data.STATUS_AUG, data.default))\n",
    "# Since P-value is < 0.05, STATUS_AUG and Default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981.2401554605125,\n",
       " 1.6716698582981148e-206,\n",
       " 8,\n",
       " array([[1.56348040e+03, 8.65519603e+02],\n",
       "        [6.43672457e-01, 3.56327543e-01],\n",
       "        [8.71532506e+02, 4.82467494e+02],\n",
       "        [7.91717122e+01, 4.38282878e+01],\n",
       "        [3.21836228e+01, 1.78163772e+01],\n",
       "        [1.28734491e+01, 7.12655087e+00],\n",
       "        [1.48044665e+01, 8.19553350e+00],\n",
       "        [1.73791563e+01, 9.62084367e+00],\n",
       "        [1.93101737e+00, 1.06898263e+00]]))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for STATUS_JUL and default\n",
    "chi2_contingency(pd.crosstab(data.STATUS_JUL, data.default))\n",
    "# Since P-value is < 0.05, STATUS_JUL and Default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1033.7951233615956,\n",
       " 7.56530541048944e-218,\n",
       " 8,\n",
       " array([[1.62012357e+03, 8.96876427e+02],\n",
       "        [6.43672457e-01, 3.56327543e-01],\n",
       "        [8.01372208e+02, 4.43627792e+02],\n",
       "        [6.88729529e+01, 3.81270471e+01],\n",
       "        [3.99076923e+01, 2.20923077e+01],\n",
       "        [2.18848635e+01, 1.21151365e+01],\n",
       "        [2.57468983e+00, 1.42531017e+00],\n",
       "        [3.73330025e+01, 2.06669975e+01],\n",
       "        [1.28734491e+00, 7.12655087e-01]]))"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for STATUS_JUN and default\n",
    "chi2_contingency(pd.crosstab(data.STATUS_JUN, data.default))\n",
    "# Since P-value is < 0.05, STATUS_JUN and Default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1055.3728694589097,\n",
       " 1.3035129394978537e-223,\n",
       " 7,\n",
       " array([[1.65166352e+03, 9.14336476e+02],\n",
       "        [7.60820844e+02, 4.21179156e+02],\n",
       "        [8.43210918e+01, 4.66789082e+01],\n",
       "        [4.82754342e+01, 2.67245658e+01],\n",
       "        [9.01141439e+00, 4.98858561e+00],\n",
       "        [2.57468983e+00, 1.42531017e+00],\n",
       "        [3.66893300e+01, 2.03106700e+01],\n",
       "        [6.43672457e-01, 3.56327543e-01]]))"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for STATUS_MAY and default\n",
    "chi2_contingency(pd.crosstab(data.STATUS_MAY, data.default))\n",
    "# Since P-value is < 0.05, STATUS_MAY and Default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1007.957072772629,\n",
       " 2.2988568833655303e-213,\n",
       " 7,\n",
       " array([[1.62720397e+03, 9.00796030e+02],\n",
       "        [8.12314640e+02, 4.49685360e+02],\n",
       "        [8.04590571e+01, 4.45409429e+01],\n",
       "        [2.63905707e+01, 1.46094293e+01],\n",
       "        [7.08039702e+00, 3.91960298e+00],\n",
       "        [9.65508685e+00, 5.34491315e+00],\n",
       "        [2.96089330e+01, 1.63910670e+01],\n",
       "        [1.28734491e+00, 7.12655087e-01]]))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chi Square test for STATUS_APR and default\n",
    "chi2_contingency(pd.crosstab(data.STATUS_APR, data.default))\n",
    "# Since P-value is < 0.05, STATUS_APR and Default are dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After doing Chi Square test for categorical variables and Logistic Regression for continuous variables\n",
    "#We remove all marriages as its p value is > 0.05, which indicates that the MARRIAGE is independent of default \n",
    "\n",
    "data.drop(columns = ['MARRIAGE_SINGLE'], inplace = True)\n",
    "data.drop(columns = ['MARRIAGE_MARRIED'], inplace = True)\n",
    "data.drop(columns = ['MARRIAGE_OTHERS'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col1 {\n",
       "            background-color:  #d8dce2;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col2 {\n",
       "            background-color:  #b1cbfc;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col0 {\n",
       "            background-color:  #e4d9d2;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col2 {\n",
       "            background-color:  #cdd9ec;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col3 {\n",
       "            background-color:  #89acfd;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col4 {\n",
       "            background-color:  #6687ed;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col5 {\n",
       "            background-color:  #5875e1;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col0 {\n",
       "            background-color:  #d4dbe6;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col1 {\n",
       "            background-color:  #dbdcde;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col3 {\n",
       "            background-color:  #94b6ff;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col4 {\n",
       "            background-color:  #8fb1fe;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col5 {\n",
       "            background-color:  #7396f5;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col0 {\n",
       "            background-color:  #7da0f9;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col1 {\n",
       "            background-color:  #a9c6fd;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col2 {\n",
       "            background-color:  #9dbdff;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col4 {\n",
       "            background-color:  #89acfd;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col5 {\n",
       "            background-color:  #81a4fb;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col0 {\n",
       "            background-color:  #9dbdff;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col1 {\n",
       "            background-color:  #a7c5fe;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col2 {\n",
       "            background-color:  #b3cdfb;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col3 {\n",
       "            background-color:  #a7c5fe;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col5 {\n",
       "            background-color:  #c9d7f0;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col3 {\n",
       "            background-color:  #3f53c6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col4 {\n",
       "            background-color:  #779af7;\n",
       "            color:  #000000;\n",
       "        }    #T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >BILL_SEP</th>        <th class=\"col_heading level0 col1\" >BILL_AUG</th>        <th class=\"col_heading level0 col2\" >BILL_JUL</th>        <th class=\"col_heading level0 col3\" >BILL_JUN</th>        <th class=\"col_heading level0 col4\" >BILL_MAY</th>        <th class=\"col_heading level0 col5\" >BILL_APR</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49level0_row0\" class=\"row_heading level0 row0\" >BILL_SEP</th>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col1\" class=\"data row0 col1\" >0.955722</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col2\" class=\"data row0 col2\" >0.949824</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col3\" class=\"data row0 col3\" >0.925006</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col4\" class=\"data row0 col4\" >0.933507</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row0_col5\" class=\"data row0 col5\" >0.905779</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49level0_row1\" class=\"row_heading level0 row1\" >BILL_AUG</th>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col0\" class=\"data row1 col0\" >0.955722</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col2\" class=\"data row1 col2\" >0.957013</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col3\" class=\"data row1 col3\" >0.942918</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col4\" class=\"data row1 col4\" >0.942664</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row1_col5\" class=\"data row1 col5\" >0.914697</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49level0_row2\" class=\"row_heading level0 row2\" >BILL_JUL</th>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col0\" class=\"data row2 col0\" >0.949824</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col1\" class=\"data row2 col1\" >0.957013</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col3\" class=\"data row2 col3\" >0.945363</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col4\" class=\"data row2 col4\" >0.950457</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row2_col5\" class=\"data row2 col5\" >0.922508</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49level0_row3\" class=\"row_heading level0 row3\" >BILL_JUN</th>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col0\" class=\"data row3 col0\" >0.925006</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col1\" class=\"data row3 col1\" >0.942918</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col2\" class=\"data row3 col2\" >0.945363</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col4\" class=\"data row3 col4\" >0.949492</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row3_col5\" class=\"data row3 col5\" >0.926353</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49level0_row4\" class=\"row_heading level0 row4\" >BILL_MAY</th>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col0\" class=\"data row4 col0\" >0.933507</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col1\" class=\"data row4 col1\" >0.942664</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col2\" class=\"data row4 col2\" >0.950457</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col3\" class=\"data row4 col3\" >0.949492</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row4_col5\" class=\"data row4 col5\" >0.946128</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49level0_row5\" class=\"row_heading level0 row5\" >BILL_APR</th>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col0\" class=\"data row5 col0\" >0.905779</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col1\" class=\"data row5 col1\" >0.914697</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col2\" class=\"data row5 col2\" >0.922508</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col3\" class=\"data row5 col3\" >0.926353</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col4\" class=\"data row5 col4\" >0.946128</td>\n",
       "                        <td id=\"T_02d7ce66_0c3b_11ea_83ec_0028f8de9a49row5_col5\" class=\"data row5 col5\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b2d8db4708>"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data[data.columns[9:15]].corr()\n",
    "corr.style.background_gradient(cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveCorr(data):\n",
    "    corr = data[data.columns[9:15]].corr()\n",
    "    columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "    realmax = 0\n",
    "    maxbilli = 0\n",
    "    for i in range(6):\n",
    "        maxinside = 0\n",
    "        for j in range(6):\n",
    "            maxinside += corr.iloc[i,j]\n",
    "        maxinside /= 6\n",
    "        if maxinside > realmax:\n",
    "            realmax = maxinside\n",
    "            maxbilli = i\n",
    "        else:\n",
    "            continue\n",
    "    print(corr.columns[maxbilli])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BILL_JUL\n"
     ]
    }
   ],
   "source": [
    "retrieveCorr(data)\n",
    "#BILL_JUL has the highest average correlation across all bills, hence, we keep this and remove the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all BILLs except BILL_JUL\n",
    "data.drop(columns = ['BILL_SEP', 'BILL_JUN', 'BILL_AUG', 'BILL_MAY', 'BILL_APR'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "#This will help to limit the range and standerdise the variables so that they can all be compared on common grounds. \n",
    "#If they do not have the same scale, it will cause problems to the machine learning that we will be applying later on(as most machine learning models is based on euclidean distance). \n",
    "#This algorithm will also converge faster.\n",
    "\n",
    "data['LIMIT_BAL'] = StandardScaler().fit_transform(data['LIMIT_BAL'].values.reshape(-1,1))\n",
    "data['BILL_JUL'] = StandardScaler().fit_transform(data['BILL_JUL'].values.reshape(-1,1))\n",
    "data['PAY_SEP'] = StandardScaler().fit_transform(data['PAY_SEP'].values.reshape(-1,1))\n",
    "data['PAY_AUG'] = StandardScaler().fit_transform(data['PAY_AUG'].values.reshape(-1,1))\n",
    "data['PAY_JUL'] = StandardScaler().fit_transform(data['PAY_JUL'].values.reshape(-1,1))\n",
    "data['PAY_JUN'] = StandardScaler().fit_transform(data['PAY_JUN'].values.reshape(-1,1))\n",
    "data['PAY_MAY'] = StandardScaler().fit_transform(data['PAY_MAY'].values.reshape(-1,1))\n",
    "data['PAY_APR'] = StandardScaler().fit_transform(data['PAY_APR'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>STATUS_SEP</th>\n",
       "      <th>STATUS_AUG</th>\n",
       "      <th>STATUS_JUL</th>\n",
       "      <th>STATUS_JUN</th>\n",
       "      <th>STATUS_MAY</th>\n",
       "      <th>STATUS_APR</th>\n",
       "      <th>BILL_JUL</th>\n",
       "      <th>PAY_SEP</th>\n",
       "      <th>PAY_AUG</th>\n",
       "      <th>PAY_JUL</th>\n",
       "      <th>PAY_JUN</th>\n",
       "      <th>PAY_MAY</th>\n",
       "      <th>PAY_APR</th>\n",
       "      <th>SEX_FEMALE</th>\n",
       "      <th>SEX_MALE</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.701530</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.277813</td>\n",
       "      <td>1.577344</td>\n",
       "      <td>0.447169</td>\n",
       "      <td>0.288158</td>\n",
       "      <td>1.600493</td>\n",
       "      <td>-0.340261</td>\n",
       "      <td>-0.063545</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>-0.410215</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.494797</td>\n",
       "      <td>-0.398662</td>\n",
       "      <td>-0.358458</td>\n",
       "      <td>-0.351930</td>\n",
       "      <td>-0.352972</td>\n",
       "      <td>-0.316917</td>\n",
       "      <td>-0.307007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>-0.966087</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.425092</td>\n",
       "      <td>-0.113868</td>\n",
       "      <td>-0.099238</td>\n",
       "      <td>-0.199497</td>\n",
       "      <td>2.333324</td>\n",
       "      <td>-0.321275</td>\n",
       "      <td>-0.307007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.463299</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.203611</td>\n",
       "      <td>1.159389</td>\n",
       "      <td>0.723921</td>\n",
       "      <td>0.791995</td>\n",
       "      <td>0.879832</td>\n",
       "      <td>2.414677</td>\n",
       "      <td>-0.307007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.654455</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.161608</td>\n",
       "      <td>1.551796</td>\n",
       "      <td>0.878952</td>\n",
       "      <td>1.488389</td>\n",
       "      <td>0.658423</td>\n",
       "      <td>0.537002</td>\n",
       "      <td>0.244862</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LIMIT_BAL  EDUCATION  AGE  STATUS_SEP  STATUS_AUG  STATUS_JUL  STATUS_JUN  \\\n",
       "ID                                                                              \n",
       "12   0.701530          1   51           0           0           0           0   \n",
       "22  -0.410215          3   39           0           0           0           0   \n",
       "29  -0.966087          2   47           0           0           0           0   \n",
       "31   0.463299          1   27           0           0           0           0   \n",
       "49   1.654455          3   32           0           0           0           0   \n",
       "\n",
       "    STATUS_MAY  STATUS_APR  BILL_JUL   PAY_SEP   PAY_AUG   PAY_JUL   PAY_JUN  \\\n",
       "ID                                                                             \n",
       "12           0           2 -0.277813  1.577344  0.447169  0.288158  1.600493   \n",
       "22           0           0 -0.494797 -0.398662 -0.358458 -0.351930 -0.352972   \n",
       "29           0           0 -0.425092 -0.113868 -0.099238 -0.199497  2.333324   \n",
       "31           0           0 -0.203611  1.159389  0.723921  0.791995  0.879832   \n",
       "49           0           0 -0.161608  1.551796  0.878952  1.488389  0.658423   \n",
       "\n",
       "     PAY_MAY   PAY_APR  SEX_FEMALE  SEX_MALE  default  \n",
       "ID                                                     \n",
       "12 -0.340261 -0.063545           1         0        0  \n",
       "22 -0.316917 -0.307007           1         0        1  \n",
       "29 -0.321275 -0.307007           1         0        0  \n",
       "31  2.414677 -0.307007           1         0        0  \n",
       "49  0.537002  0.244862           0         1        0  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Describing the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"processed_data_BT2101.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliiting test and train set (to be done after feature selection)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = data.iloc[:, :-1].values\n",
    "y = data[\"default\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3224, 18), (3224,), (806, 18), (806,))"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBF Kernel\n",
    "rbf_svc = SVC(kernel = 'rbf', C = 1, gamma = 0.01, probability = True)\n",
    "rbf_svc.fit(x_train,y_train)\n",
    "\n",
    "#Predict\n",
    "y_rbf_pred = rbf_svc.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[444  84]\n",
      " [ 85 193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       528\n",
      "           1       0.70      0.69      0.70       278\n",
      "\n",
      "    accuracy                           0.79       806\n",
      "   macro avg       0.77      0.77      0.77       806\n",
      "weighted avg       0.79      0.79      0.79       806\n",
      "\n",
      "The SSE for rbf kernel is :169.0\n",
      "The MSE for rbf kernel is :0.20967741935483872\n",
      "The RMSE for rbf kernel is :0.4579054698896255\n",
      "The Adjusted R^2 for rbf kernel is :0.07316192500546082\n",
      "The ROC is : 0.767577\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.696751</td>\n",
       "      <td>0.694245</td>\n",
       "      <td>0.695495</td>\n",
       "      <td>0.767577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy  Precision    Recall  F1 Score       ROC\n",
       "0  Support Vector Machine  0.790323   0.696751  0.694245  0.695495  0.767577"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation\n",
    "cm = confusion_matrix(y_test, y_rbf_pred)\n",
    "cr = classification_report(y_test, y_rbf_pred)\n",
    "print(cm)\n",
    "print(cr)\n",
    "\n",
    "acc_rbf = metrics.accuracy_score(y_test, y_rbf_pred)\n",
    "prec_rbf = metrics.precision_score(y_test,y_rbf_pred)\n",
    "rec_rbf = metrics.recall_score(y_test,y_rbf_pred)\n",
    "f1_rbf = metrics.f1_score(y_test,y_rbf_pred)\n",
    "\n",
    "#SSE\n",
    "#Number of observations = 806\n",
    "SSE = 806*(metrics.mean_squared_error(y_test, y_rbf_pred))\n",
    "print('The SSE for RBF kernel is :' + str(SSE))\n",
    "\n",
    "#MSE\n",
    "MSE = metrics.mean_squared_error(y_test,y_rbf_pred)\n",
    "print('The MSE for RBF kernel is :' + str(MSE))\n",
    "\n",
    "#RMSE\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test,y_rbf_pred))\n",
    "print('The RMSE for RBF kernel is :' + str(RMSE))\n",
    "\n",
    "#Adjusted R^2\n",
    "var_test = y_test.var()\n",
    "adj_rsquare = 1-(MSE/var_test)\n",
    "print('The Adjusted R^2 for RBF kernel is :' + str(adj_rsquare))\n",
    "\n",
    "#ROC \n",
    "prob_rbf = rbf_svc.fit(x_train, y_train).predict_proba(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_rbf[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_rbf = metrics.roc_auc_score(y_test, y_rbf_pred)\n",
    "print(\"The ROC is : %f\" % roc_rbf)\n",
    "\n",
    "model = pd.DataFrame([['Support Vector Machine', acc_rbf,prec_rbf,rec_rbf, f1_rbf,roc_rbf]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score','ROC'])\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve : 0.813174\n"
     ]
    }
   ],
   "source": [
    "# Plot ROC curve\n",
    "pl.clf()\n",
    "pl.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "pl.plot([0, 1], [0, 1], 'k--')\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.0])\n",
    "pl.xlabel('False Positive Rate')\n",
    "pl.ylabel('True Positive Rate')\n",
    "pl.title('AUROC')\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.1, gamma=10 .................................................\n",
      "[CV] ..................... C=0.1, gamma=10, score=0.644, total=   1.2s\n",
      "[CV] C=0.1, gamma=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=0.1, gamma=10, score=0.644, total=   1.2s\n",
      "[CV] C=0.1, gamma=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=0.1, gamma=10, score=0.644, total=   1.7s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=0.1, gamma=1, score=0.644, total=   1.3s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=0.1, gamma=1, score=0.644, total=   0.7s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ...................... C=0.1, gamma=1, score=0.644, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.766, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.738, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.752, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.797, total=   0.4s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.767, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.774, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .................. C=0.1, gamma=0.001, score=0.739, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .................. C=0.1, gamma=0.001, score=0.741, total=   0.5s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .................. C=0.1, gamma=0.001, score=0.747, total=   0.5s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] ....................... C=1, gamma=10, score=0.645, total=   1.3s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] ....................... C=1, gamma=10, score=0.648, total=   1.3s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] ....................... C=1, gamma=10, score=0.650, total=   1.4s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.698, total=   1.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.695, total=   0.8s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.698, total=   0.8s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.785, total=   0.5s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.756, total=   0.5s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.761, total=   0.5s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.799, total=   0.4s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.765, total=   0.4s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.774, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.798, total=   0.6s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.767, total=   0.7s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.775, total=   0.8s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ...................... C=10, gamma=10, score=0.643, total=   1.4s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ...................... C=10, gamma=10, score=0.648, total=   1.1s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ...................... C=10, gamma=10, score=0.648, total=   1.2s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.673, total=   0.7s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.678, total=   0.5s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.694, total=   0.8s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.753, total=   0.5s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.735, total=   0.4s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.733, total=   0.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.795, total=   0.3s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.767, total=   0.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.765, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.798, total=   0.3s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.764, total=   0.3s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.773, total=   0.2s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ..................... C=100, gamma=10, score=0.644, total=   1.0s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ..................... C=100, gamma=10, score=0.647, total=   1.0s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ..................... C=100, gamma=10, score=0.647, total=   1.1s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ...................... C=100, gamma=1, score=0.670, total=   0.5s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ...................... C=100, gamma=1, score=0.669, total=   0.5s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ...................... C=100, gamma=1, score=0.679, total=   0.5s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] .................... C=100, gamma=0.1, score=0.710, total=   0.9s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] .................... C=100, gamma=0.1, score=0.705, total=   0.8s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] .................... C=100, gamma=0.1, score=0.714, total=   0.7s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.777, total=   1.2s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.758, total=   1.7s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.753, total=   1.8s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.796, total=   0.7s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.763, total=   0.7s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.767, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   45.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'C': 1, 'gamma': 0.001}\n",
      "Best Estimators:\n",
      " SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Finding best parameter\n",
    "# Grid Search\n",
    "# Parameter Grid\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [10,1, 0.1, 0.01, 0.001]}\n",
    " \n",
    "# Make grid search classifier\n",
    "clf_grid = GridSearchCV(svm.SVC(), param_grid, verbose=5)\n",
    " \n",
    "# Train the classifier\n",
    "clf_grid.fit(x_train, y_train)\n",
    " \n",
    "# clf = grid.best_estimator_()\n",
    "print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
    "print(\"Best Estimators:\\n\", clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid Kernel\n",
    "sig_svc = SVC(kernel='sigmoid', gamma = 1, C = 0.1)\n",
    "sig_svc.fit(x_train, y_train)\n",
    "y_svc_pred = sig_svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[522   0]\n",
      " [284   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       522\n",
      "           1       0.00      0.00      0.00       284\n",
      "\n",
      "    accuracy                           0.65       806\n",
      "   macro avg       0.32      0.50      0.39       806\n",
      "weighted avg       0.42      0.65      0.51       806\n",
      "\n",
      "0.786144578313253\n",
      "0.6476426799007444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huang\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "cm = confusion_matrix(y_test, y_svc_pred)\n",
    "cr = classification_report(y_test, y_svc_pred)\n",
    "print(cm)\n",
    "print(cr)\n",
    "print(metrics.f1_score(y_test, y_svc_pred, average='weighted', labels=np.unique(y_svc_pred)))\n",
    "print(metrics.precision_score(y_test, y_svc_pred, average= 'weighted', labels=np.unique(y_svc_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huang\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.1, gamma=10 .................................................\n",
      "[CV] ..................... C=0.1, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=0.1, gamma=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=0.1, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=0.1, gamma=10 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=0.1, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=0.1, gamma=1, score=0.644, total=   0.4s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... C=0.1, gamma=1, score=0.644, total=   0.6s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ...................... C=0.1, gamma=1, score=0.644, total=   0.7s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.644, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.644, total=   0.4s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] .................... C=0.1, gamma=0.1, score=0.644, total=   0.3s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.644, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.644, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................... C=0.1, gamma=0.01, score=0.644, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .................. C=0.1, gamma=0.001, score=0.579, total=   0.9s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .................. C=0.1, gamma=0.001, score=0.602, total=   0.6s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .................. C=0.1, gamma=0.001, score=0.589, total=   0.6s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] ....................... C=1, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] ....................... C=1, gamma=10, score=0.644, total=   0.4s\n",
      "[CV] C=1, gamma=10 ...................................................\n",
      "[CV] ....................... C=1, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.644, total=   0.3s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.644, total=   0.4s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........................ C=1, gamma=1, score=0.644, total=   0.4s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.644, total=   0.3s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.644, total=   0.3s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ...................... C=1, gamma=0.1, score=0.644, total=   0.2s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.644, total=   0.6s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.644, total=   0.8s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.644, total=   0.9s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.534, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.559, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.549, total=   0.4s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ...................... C=10, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ...................... C=10, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=10 ..................................................\n",
      "[CV] ...................... C=10, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ....................... C=10, gamma=1, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ..................... C=10, gamma=0.1, score=0.644, total=   0.3s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.644, total=   0.7s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.644, total=   0.9s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.644, total=   1.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.540, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.567, total=   0.3s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.549, total=   0.3s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ..................... C=100, gamma=10, score=0.644, total=   0.2s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ..................... C=100, gamma=10, score=0.644, total=   0.2s\n",
      "[CV] C=100, gamma=10 .................................................\n",
      "[CV] ..................... C=100, gamma=10, score=0.644, total=   0.3s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ...................... C=100, gamma=1, score=0.644, total=   0.2s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ...................... C=100, gamma=1, score=0.644, total=   0.3s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ...................... C=100, gamma=1, score=0.644, total=   0.2s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] .................... C=100, gamma=0.1, score=0.644, total=   0.2s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] .................... C=100, gamma=0.1, score=0.644, total=   0.2s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] .................... C=100, gamma=0.1, score=0.644, total=   0.3s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.644, total=   0.8s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.644, total=   0.8s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.644, total=   1.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.533, total=   0.5s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.563, total=   0.7s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.550, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   27.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      " {'C': 0.1, 'gamma': 10}\n",
      "Best Estimators:\n",
      " SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=10, kernel='sigmoid',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# Finding best parameter\n",
    "# Grid Search\n",
    "# Parameter Grid\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [10,1, 0.1, 0.01, 0.001]}\n",
    " \n",
    "# Make grid search classifier\n",
    "clf_grid = GridSearchCV(svm.SVC(kernel = 'sigmoid'), param_grid, verbose=5)\n",
    " \n",
    "# Train the classifier\n",
    "clf_grid.fit(x_train, y_train)\n",
    " \n",
    "# clf = grid.best_estimator_()\n",
    "print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
    "print(\"Best Estimators:\\n\", clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-d81b3c750ae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Neural Network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Neural Network\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#defifne a sequentail Model\n",
    "model = Sequential()\n",
    "\n",
    "#Hidden Layer-1\n",
    "model.add(Dense(100,activation='relu',input_dim=18,kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "#Hidden Layer-2\n",
    "model.add(Dense(100,activation = 'relu',kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-202-7017d27df329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 100)               1900      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 12,101\n",
      "Trainable params: 12,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3233 samples, validate on 809 samples\n",
      "Epoch 1/500\n",
      "3233/3233 [==============================] - 1s 217us/step - loss: 1.4897 - accuracy: 0.6650 - val_loss: 0.9644 - val_accuracy: 0.8010\n",
      "Epoch 2/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.9369 - accuracy: 0.7269 - val_loss: 0.7981 - val_accuracy: 0.7985\n",
      "Epoch 3/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.8154 - accuracy: 0.7393 - val_loss: 0.7143 - val_accuracy: 0.7985\n",
      "Epoch 4/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.7390 - accuracy: 0.7572 - val_loss: 0.6605 - val_accuracy: 0.7973\n",
      "Epoch 5/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.6972 - accuracy: 0.7572 - val_loss: 0.6363 - val_accuracy: 0.7948\n",
      "Epoch 6/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.6536 - accuracy: 0.7597 - val_loss: 0.5929 - val_accuracy: 0.7985\n",
      "Epoch 7/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.6253 - accuracy: 0.7655 - val_loss: 0.5769 - val_accuracy: 0.7985\n",
      "Epoch 8/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.6040 - accuracy: 0.7677 - val_loss: 0.5553 - val_accuracy: 0.8010\n",
      "Epoch 9/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5853 - accuracy: 0.7686 - val_loss: 0.5399 - val_accuracy: 0.7985\n",
      "Epoch 10/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5734 - accuracy: 0.7754 - val_loss: 0.5362 - val_accuracy: 0.7985\n",
      "Epoch 11/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5695 - accuracy: 0.7696 - val_loss: 0.5285 - val_accuracy: 0.8035\n",
      "Epoch 12/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5516 - accuracy: 0.7733 - val_loss: 0.5166 - val_accuracy: 0.7985\n",
      "Epoch 13/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5450 - accuracy: 0.7696 - val_loss: 0.5120 - val_accuracy: 0.8022\n",
      "Epoch 14/500\n",
      "3233/3233 [==============================] - 0s 70us/step - loss: 0.5412 - accuracy: 0.7714 - val_loss: 0.5073 - val_accuracy: 0.8010\n",
      "Epoch 15/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5356 - accuracy: 0.7748 - val_loss: 0.5049 - val_accuracy: 0.8022\n",
      "Epoch 16/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5348 - accuracy: 0.7727 - val_loss: 0.5068 - val_accuracy: 0.7985\n",
      "Epoch 17/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5337 - accuracy: 0.7776 - val_loss: 0.5006 - val_accuracy: 0.8035\n",
      "Epoch 18/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5312 - accuracy: 0.7723 - val_loss: 0.4992 - val_accuracy: 0.8010\n",
      "Epoch 19/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5266 - accuracy: 0.7745 - val_loss: 0.5067 - val_accuracy: 0.7985\n",
      "Epoch 20/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5267 - accuracy: 0.7714 - val_loss: 0.4958 - val_accuracy: 0.8047\n",
      "Epoch 21/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5258 - accuracy: 0.7770 - val_loss: 0.4952 - val_accuracy: 0.8010\n",
      "Epoch 22/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5279 - accuracy: 0.7720 - val_loss: 0.5046 - val_accuracy: 0.7960\n",
      "Epoch 23/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5243 - accuracy: 0.7711 - val_loss: 0.4986 - val_accuracy: 0.8022\n",
      "Epoch 24/500\n",
      "3233/3233 [==============================] - 0s 72us/step - loss: 0.5267 - accuracy: 0.7717 - val_loss: 0.4966 - val_accuracy: 0.8022\n",
      "Epoch 25/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5234 - accuracy: 0.7754 - val_loss: 0.4955 - val_accuracy: 0.8010\n",
      "Epoch 26/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5278 - accuracy: 0.7702 - val_loss: 0.4959 - val_accuracy: 0.8010\n",
      "Epoch 27/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5237 - accuracy: 0.7689 - val_loss: 0.4966 - val_accuracy: 0.8022\n",
      "Epoch 28/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5256 - accuracy: 0.7720 - val_loss: 0.4987 - val_accuracy: 0.7985\n",
      "Epoch 29/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5259 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.8035\n",
      "Epoch 30/500\n",
      "3233/3233 [==============================] - 0s 71us/step - loss: 0.5223 - accuracy: 0.7758 - val_loss: 0.5031 - val_accuracy: 0.7886\n",
      "Epoch 31/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5238 - accuracy: 0.7733 - val_loss: 0.5051 - val_accuracy: 0.8035\n",
      "Epoch 32/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5281 - accuracy: 0.7686 - val_loss: 0.4951 - val_accuracy: 0.7985\n",
      "Epoch 33/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5205 - accuracy: 0.7727 - val_loss: 0.4967 - val_accuracy: 0.8022\n",
      "Epoch 34/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5198 - accuracy: 0.7745 - val_loss: 0.4968 - val_accuracy: 0.7948\n",
      "Epoch 35/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5207 - accuracy: 0.7751 - val_loss: 0.5009 - val_accuracy: 0.7948\n",
      "Epoch 36/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5229 - accuracy: 0.7739 - val_loss: 0.4921 - val_accuracy: 0.7998\n",
      "Epoch 37/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5206 - accuracy: 0.7754 - val_loss: 0.4963 - val_accuracy: 0.7985\n",
      "Epoch 38/500\n",
      "3233/3233 [==============================] - 0s 71us/step - loss: 0.5163 - accuracy: 0.7720 - val_loss: 0.5114 - val_accuracy: 0.7911\n",
      "Epoch 39/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5218 - accuracy: 0.7708 - val_loss: 0.4912 - val_accuracy: 0.8035\n",
      "Epoch 40/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5211 - accuracy: 0.7668 - val_loss: 0.4939 - val_accuracy: 0.7948\n",
      "Epoch 41/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5141 - accuracy: 0.7785 - val_loss: 0.4905 - val_accuracy: 0.8022\n",
      "Epoch 42/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5230 - accuracy: 0.7696 - val_loss: 0.4923 - val_accuracy: 0.8035\n",
      "Epoch 43/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5189 - accuracy: 0.7727 - val_loss: 0.4927 - val_accuracy: 0.8022\n",
      "Epoch 44/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5219 - accuracy: 0.7668 - val_loss: 0.4913 - val_accuracy: 0.8022\n",
      "Epoch 45/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5185 - accuracy: 0.7733 - val_loss: 0.4992 - val_accuracy: 0.7998\n",
      "Epoch 46/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5219 - accuracy: 0.7720 - val_loss: 0.4934 - val_accuracy: 0.7985\n",
      "Epoch 47/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5182 - accuracy: 0.7668 - val_loss: 0.4915 - val_accuracy: 0.8010\n",
      "Epoch 48/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5213 - accuracy: 0.7683 - val_loss: 0.4954 - val_accuracy: 0.8035\n",
      "Epoch 49/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5192 - accuracy: 0.7804 - val_loss: 0.4912 - val_accuracy: 0.8010\n",
      "Epoch 50/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5189 - accuracy: 0.7730 - val_loss: 0.4929 - val_accuracy: 0.7973\n",
      "Epoch 51/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5181 - accuracy: 0.7717 - val_loss: 0.4931 - val_accuracy: 0.7960\n",
      "Epoch 52/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5191 - accuracy: 0.7711 - val_loss: 0.4936 - val_accuracy: 0.8022\n",
      "Epoch 53/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5224 - accuracy: 0.7758 - val_loss: 0.4940 - val_accuracy: 0.7998\n",
      "Epoch 54/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5162 - accuracy: 0.7761 - val_loss: 0.4926 - val_accuracy: 0.8047\n",
      "Epoch 55/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5227 - accuracy: 0.7736 - val_loss: 0.4956 - val_accuracy: 0.8010\n",
      "Epoch 56/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5196 - accuracy: 0.7751 - val_loss: 0.4923 - val_accuracy: 0.7973\n",
      "Epoch 57/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5166 - accuracy: 0.7773 - val_loss: 0.4915 - val_accuracy: 0.7985\n",
      "Epoch 58/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5203 - accuracy: 0.7727 - val_loss: 0.4938 - val_accuracy: 0.8035\n",
      "Epoch 59/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5215 - accuracy: 0.7770 - val_loss: 0.5039 - val_accuracy: 0.7923\n",
      "Epoch 60/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5196 - accuracy: 0.7723 - val_loss: 0.4934 - val_accuracy: 0.7985\n",
      "Epoch 61/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5222 - accuracy: 0.7764 - val_loss: 0.4912 - val_accuracy: 0.8035\n",
      "Epoch 62/500\n",
      "3233/3233 [==============================] - 0s 71us/step - loss: 0.5185 - accuracy: 0.7714 - val_loss: 0.4962 - val_accuracy: 0.8010\n",
      "Epoch 63/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5195 - accuracy: 0.7717 - val_loss: 0.5044 - val_accuracy: 0.7985\n",
      "Epoch 64/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5214 - accuracy: 0.7668 - val_loss: 0.4952 - val_accuracy: 0.8010\n",
      "Epoch 65/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5183 - accuracy: 0.7733 - val_loss: 0.4937 - val_accuracy: 0.7948\n",
      "Epoch 66/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5178 - accuracy: 0.7699 - val_loss: 0.4908 - val_accuracy: 0.7985\n",
      "Epoch 67/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5173 - accuracy: 0.7767 - val_loss: 0.4891 - val_accuracy: 0.8047\n",
      "Epoch 68/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5141 - accuracy: 0.7727 - val_loss: 0.5020 - val_accuracy: 0.7948\n",
      "Epoch 69/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5224 - accuracy: 0.7702 - val_loss: 0.4895 - val_accuracy: 0.8022\n",
      "Epoch 70/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5184 - accuracy: 0.7727 - val_loss: 0.5021 - val_accuracy: 0.8010\n",
      "Epoch 71/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5192 - accuracy: 0.7739 - val_loss: 0.4901 - val_accuracy: 0.8010\n",
      "Epoch 72/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5225 - accuracy: 0.7764 - val_loss: 0.4925 - val_accuracy: 0.7973\n",
      "Epoch 73/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5247 - accuracy: 0.7711 - val_loss: 0.4912 - val_accuracy: 0.8010\n",
      "Epoch 74/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5194 - accuracy: 0.7745 - val_loss: 0.4908 - val_accuracy: 0.7985\n",
      "Epoch 75/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5184 - accuracy: 0.7764 - val_loss: 0.4913 - val_accuracy: 0.8035\n",
      "Epoch 76/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5172 - accuracy: 0.7742 - val_loss: 0.4885 - val_accuracy: 0.8035\n",
      "Epoch 77/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5190 - accuracy: 0.7742 - val_loss: 0.4922 - val_accuracy: 0.7985\n",
      "Epoch 78/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5236 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.8010\n",
      "Epoch 79/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5180 - accuracy: 0.7758 - val_loss: 0.4896 - val_accuracy: 0.8010\n",
      "Epoch 80/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5173 - accuracy: 0.7745 - val_loss: 0.4933 - val_accuracy: 0.7985\n",
      "Epoch 81/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5198 - accuracy: 0.7720 - val_loss: 0.5168 - val_accuracy: 0.7911\n",
      "Epoch 82/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5180 - accuracy: 0.7748 - val_loss: 0.4922 - val_accuracy: 0.7998\n",
      "Epoch 83/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5196 - accuracy: 0.7730 - val_loss: 0.4998 - val_accuracy: 0.8047\n",
      "Epoch 84/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5183 - accuracy: 0.7730 - val_loss: 0.5161 - val_accuracy: 0.7738\n",
      "Epoch 85/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5162 - accuracy: 0.7792 - val_loss: 0.4907 - val_accuracy: 0.8022\n",
      "Epoch 86/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5211 - accuracy: 0.7693 - val_loss: 0.5036 - val_accuracy: 0.7960\n",
      "Epoch 87/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5163 - accuracy: 0.7776 - val_loss: 0.4881 - val_accuracy: 0.8035\n",
      "Epoch 88/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5234 - accuracy: 0.7736 - val_loss: 0.4988 - val_accuracy: 0.8010\n",
      "Epoch 89/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5188 - accuracy: 0.7717 - val_loss: 0.4965 - val_accuracy: 0.7960\n",
      "Epoch 90/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5212 - accuracy: 0.7714 - val_loss: 0.4923 - val_accuracy: 0.8022\n",
      "Epoch 91/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5210 - accuracy: 0.7727 - val_loss: 0.4885 - val_accuracy: 0.8035\n",
      "Epoch 92/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5174 - accuracy: 0.7764 - val_loss: 0.4930 - val_accuracy: 0.7985\n",
      "Epoch 93/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5186 - accuracy: 0.7711 - val_loss: 0.4962 - val_accuracy: 0.8010\n",
      "Epoch 94/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5160 - accuracy: 0.7742 - val_loss: 0.4894 - val_accuracy: 0.8035\n",
      "Epoch 95/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5162 - accuracy: 0.7745 - val_loss: 0.4898 - val_accuracy: 0.7998\n",
      "Epoch 96/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5149 - accuracy: 0.7723 - val_loss: 0.5021 - val_accuracy: 0.8010\n",
      "Epoch 97/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5174 - accuracy: 0.7748 - val_loss: 0.4929 - val_accuracy: 0.7985\n",
      "Epoch 98/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5170 - accuracy: 0.7727 - val_loss: 0.4884 - val_accuracy: 0.8022\n",
      "Epoch 99/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5230 - accuracy: 0.7745 - val_loss: 0.4923 - val_accuracy: 0.8035\n",
      "Epoch 100/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5188 - accuracy: 0.7717 - val_loss: 0.4936 - val_accuracy: 0.8035\n",
      "Epoch 101/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5170 - accuracy: 0.7739 - val_loss: 0.5091 - val_accuracy: 0.7936\n",
      "Epoch 102/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5197 - accuracy: 0.7696 - val_loss: 0.4907 - val_accuracy: 0.7998\n",
      "Epoch 103/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5202 - accuracy: 0.7754 - val_loss: 0.4897 - val_accuracy: 0.8010\n",
      "Epoch 104/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5137 - accuracy: 0.7733 - val_loss: 0.4936 - val_accuracy: 0.8047\n",
      "Epoch 105/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5197 - accuracy: 0.7751 - val_loss: 0.4941 - val_accuracy: 0.7998\n",
      "Epoch 106/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5193 - accuracy: 0.7711 - val_loss: 0.4934 - val_accuracy: 0.7998\n",
      "Epoch 107/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5219 - accuracy: 0.7689 - val_loss: 0.4930 - val_accuracy: 0.8022\n",
      "Epoch 108/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5159 - accuracy: 0.7751 - val_loss: 0.4898 - val_accuracy: 0.8022\n",
      "Epoch 109/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5224 - accuracy: 0.7720 - val_loss: 0.5077 - val_accuracy: 0.7985\n",
      "Epoch 110/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5210 - accuracy: 0.7730 - val_loss: 0.4965 - val_accuracy: 0.7998\n",
      "Epoch 111/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5158 - accuracy: 0.7745 - val_loss: 0.4883 - val_accuracy: 0.8022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5167 - accuracy: 0.7689 - val_loss: 0.4900 - val_accuracy: 0.8047\n",
      "Epoch 113/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5150 - accuracy: 0.7742 - val_loss: 0.4933 - val_accuracy: 0.7948\n",
      "Epoch 114/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5180 - accuracy: 0.7782 - val_loss: 0.4959 - val_accuracy: 0.7973\n",
      "Epoch 115/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5179 - accuracy: 0.7745 - val_loss: 0.4907 - val_accuracy: 0.7973\n",
      "Epoch 116/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5165 - accuracy: 0.7727 - val_loss: 0.4923 - val_accuracy: 0.8022\n",
      "Epoch 117/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5160 - accuracy: 0.7727 - val_loss: 0.4889 - val_accuracy: 0.8022\n",
      "Epoch 118/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5168 - accuracy: 0.7779 - val_loss: 0.4884 - val_accuracy: 0.7985\n",
      "Epoch 119/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5162 - accuracy: 0.7754 - val_loss: 0.4890 - val_accuracy: 0.7998\n",
      "Epoch 120/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5163 - accuracy: 0.7739 - val_loss: 0.4903 - val_accuracy: 0.8022\n",
      "Epoch 121/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5199 - accuracy: 0.7705 - val_loss: 0.4953 - val_accuracy: 0.7973\n",
      "Epoch 122/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5198 - accuracy: 0.7745 - val_loss: 0.4901 - val_accuracy: 0.8035\n",
      "Epoch 123/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5163 - accuracy: 0.7745 - val_loss: 0.4946 - val_accuracy: 0.7948\n",
      "Epoch 124/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5194 - accuracy: 0.7702 - val_loss: 0.4936 - val_accuracy: 0.7973\n",
      "Epoch 125/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5186 - accuracy: 0.7739 - val_loss: 0.4921 - val_accuracy: 0.8022\n",
      "Epoch 126/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5168 - accuracy: 0.7730 - val_loss: 0.4969 - val_accuracy: 0.7973\n",
      "Epoch 127/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5161 - accuracy: 0.7751 - val_loss: 0.4962 - val_accuracy: 0.7960\n",
      "Epoch 128/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5145 - accuracy: 0.7748 - val_loss: 0.4910 - val_accuracy: 0.7998\n",
      "Epoch 129/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5164 - accuracy: 0.7754 - val_loss: 0.4901 - val_accuracy: 0.7973\n",
      "Epoch 130/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5177 - accuracy: 0.7733 - val_loss: 0.4961 - val_accuracy: 0.8035\n",
      "Epoch 131/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5135 - accuracy: 0.7764 - val_loss: 0.4947 - val_accuracy: 0.7936\n",
      "Epoch 132/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5201 - accuracy: 0.7711 - val_loss: 0.4895 - val_accuracy: 0.8035\n",
      "Epoch 133/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5188 - accuracy: 0.7742 - val_loss: 0.4927 - val_accuracy: 0.7960\n",
      "Epoch 134/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5168 - accuracy: 0.7736 - val_loss: 0.4917 - val_accuracy: 0.7985\n",
      "Epoch 135/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5187 - accuracy: 0.7717 - val_loss: 0.4885 - val_accuracy: 0.8035\n",
      "Epoch 136/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5169 - accuracy: 0.7754 - val_loss: 0.4880 - val_accuracy: 0.8022\n",
      "Epoch 137/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5167 - accuracy: 0.7739 - val_loss: 0.4890 - val_accuracy: 0.7973\n",
      "Epoch 138/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5179 - accuracy: 0.7717 - val_loss: 0.4921 - val_accuracy: 0.8022\n",
      "Epoch 139/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5168 - accuracy: 0.7733 - val_loss: 0.4903 - val_accuracy: 0.7985\n",
      "Epoch 140/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5170 - accuracy: 0.7761 - val_loss: 0.4902 - val_accuracy: 0.8010\n",
      "Epoch 141/500\n",
      "3233/3233 [==============================] - 0s 88us/step - loss: 0.5164 - accuracy: 0.7714 - val_loss: 0.4971 - val_accuracy: 0.7998\n",
      "Epoch 142/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5130 - accuracy: 0.7776 - val_loss: 0.4885 - val_accuracy: 0.8022\n",
      "Epoch 143/500\n",
      "3233/3233 [==============================] - 0s 86us/step - loss: 0.5172 - accuracy: 0.7736 - val_loss: 0.4885 - val_accuracy: 0.8022\n",
      "Epoch 144/500\n",
      "3233/3233 [==============================] - 0s 93us/step - loss: 0.5176 - accuracy: 0.7751 - val_loss: 0.4887 - val_accuracy: 0.7985\n",
      "Epoch 145/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5125 - accuracy: 0.7714 - val_loss: 0.4945 - val_accuracy: 0.7960\n",
      "Epoch 146/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5174 - accuracy: 0.7723 - val_loss: 0.4898 - val_accuracy: 0.8022\n",
      "Epoch 147/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5161 - accuracy: 0.7702 - val_loss: 0.4958 - val_accuracy: 0.7985\n",
      "Epoch 148/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5129 - accuracy: 0.7739 - val_loss: 0.4906 - val_accuracy: 0.7998\n",
      "Epoch 149/500\n",
      "3233/3233 [==============================] - 0s 78us/step - loss: 0.5148 - accuracy: 0.7723 - val_loss: 0.4890 - val_accuracy: 0.8022\n",
      "Epoch 150/500\n",
      "3233/3233 [==============================] - 0s 96us/step - loss: 0.5180 - accuracy: 0.7693 - val_loss: 0.5030 - val_accuracy: 0.7973\n",
      "Epoch 151/500\n",
      "3233/3233 [==============================] - 0s 85us/step - loss: 0.5135 - accuracy: 0.7748 - val_loss: 0.5024 - val_accuracy: 0.7936\n",
      "Epoch 152/500\n",
      "3233/3233 [==============================] - 0s 86us/step - loss: 0.5119 - accuracy: 0.7699 - val_loss: 0.4945 - val_accuracy: 0.7973\n",
      "Epoch 153/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5138 - accuracy: 0.7767 - val_loss: 0.4876 - val_accuracy: 0.7985\n",
      "Epoch 154/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5151 - accuracy: 0.7751 - val_loss: 0.4983 - val_accuracy: 0.7985\n",
      "Epoch 155/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5146 - accuracy: 0.7751 - val_loss: 0.4883 - val_accuracy: 0.8022\n",
      "Epoch 156/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5130 - accuracy: 0.7770 - val_loss: 0.4897 - val_accuracy: 0.7998\n",
      "Epoch 157/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5203 - accuracy: 0.7742 - val_loss: 0.4886 - val_accuracy: 0.8010\n",
      "Epoch 158/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5140 - accuracy: 0.7748 - val_loss: 0.4943 - val_accuracy: 0.8035\n",
      "Epoch 159/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5154 - accuracy: 0.7742 - val_loss: 0.4951 - val_accuracy: 0.8035\n",
      "Epoch 160/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5166 - accuracy: 0.7730 - val_loss: 0.4916 - val_accuracy: 0.8010\n",
      "Epoch 161/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5185 - accuracy: 0.7739 - val_loss: 0.4918 - val_accuracy: 0.7973\n",
      "Epoch 162/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5214 - accuracy: 0.7748 - val_loss: 0.4921 - val_accuracy: 0.8035\n",
      "Epoch 163/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5137 - accuracy: 0.7742 - val_loss: 0.4933 - val_accuracy: 0.7973\n",
      "Epoch 164/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5201 - accuracy: 0.7764 - val_loss: 0.4915 - val_accuracy: 0.8022\n",
      "Epoch 165/500\n",
      "3233/3233 [==============================] - 0s 79us/step - loss: 0.5150 - accuracy: 0.7723 - val_loss: 0.4914 - val_accuracy: 0.8035\n",
      "Epoch 166/500\n",
      "3233/3233 [==============================] - 0s 70us/step - loss: 0.5179 - accuracy: 0.7733 - val_loss: 0.4921 - val_accuracy: 0.7985\n",
      "Epoch 167/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5119 - accuracy: 0.7754 - val_loss: 0.4956 - val_accuracy: 0.7973\n",
      "Epoch 168/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5187 - accuracy: 0.7761 - val_loss: 0.4918 - val_accuracy: 0.8022\n",
      "Epoch 169/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5139 - accuracy: 0.7751 - val_loss: 0.4945 - val_accuracy: 0.8010\n",
      "Epoch 170/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5182 - accuracy: 0.7705 - val_loss: 0.4882 - val_accuracy: 0.8010\n",
      "Epoch 171/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5128 - accuracy: 0.7727 - val_loss: 0.4892 - val_accuracy: 0.7998\n",
      "Epoch 172/500\n",
      "3233/3233 [==============================] - 0s 76us/step - loss: 0.5164 - accuracy: 0.7720 - val_loss: 0.4895 - val_accuracy: 0.8022\n",
      "Epoch 173/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5137 - accuracy: 0.7764 - val_loss: 0.5128 - val_accuracy: 0.7824\n",
      "Epoch 174/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5132 - accuracy: 0.7773 - val_loss: 0.4906 - val_accuracy: 0.8010\n",
      "Epoch 175/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5126 - accuracy: 0.7717 - val_loss: 0.5001 - val_accuracy: 0.7923\n",
      "Epoch 176/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5173 - accuracy: 0.7702 - val_loss: 0.5003 - val_accuracy: 0.7936\n",
      "Epoch 177/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5183 - accuracy: 0.7723 - val_loss: 0.4867 - val_accuracy: 0.8035\n",
      "Epoch 178/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5180 - accuracy: 0.7683 - val_loss: 0.4903 - val_accuracy: 0.7948\n",
      "Epoch 179/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5149 - accuracy: 0.7736 - val_loss: 0.4860 - val_accuracy: 0.8022\n",
      "Epoch 180/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5189 - accuracy: 0.7702 - val_loss: 0.4879 - val_accuracy: 0.7985\n",
      "Epoch 181/500\n",
      "3233/3233 [==============================] - 0s 80us/step - loss: 0.5164 - accuracy: 0.7764 - val_loss: 0.4905 - val_accuracy: 0.7973\n",
      "Epoch 182/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5122 - accuracy: 0.7782 - val_loss: 0.4906 - val_accuracy: 0.7998\n",
      "Epoch 183/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5169 - accuracy: 0.7711 - val_loss: 0.4877 - val_accuracy: 0.7985\n",
      "Epoch 184/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5148 - accuracy: 0.7699 - val_loss: 0.4885 - val_accuracy: 0.7985\n",
      "Epoch 185/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5193 - accuracy: 0.7723 - val_loss: 0.4945 - val_accuracy: 0.7960\n",
      "Epoch 186/500\n",
      "3233/3233 [==============================] - 0s 70us/step - loss: 0.5200 - accuracy: 0.7770 - val_loss: 0.4916 - val_accuracy: 0.7936\n",
      "Epoch 187/500\n",
      "3233/3233 [==============================] - 0s 83us/step - loss: 0.5175 - accuracy: 0.7727 - val_loss: 0.4966 - val_accuracy: 0.8010\n",
      "Epoch 188/500\n",
      "3233/3233 [==============================] - 0s 73us/step - loss: 0.5201 - accuracy: 0.7758 - val_loss: 0.4961 - val_accuracy: 0.7998\n",
      "Epoch 189/500\n",
      "3233/3233 [==============================] - 0s 74us/step - loss: 0.5179 - accuracy: 0.7773 - val_loss: 0.4894 - val_accuracy: 0.7960\n",
      "Epoch 190/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5131 - accuracy: 0.7733 - val_loss: 0.4930 - val_accuracy: 0.7923\n",
      "Epoch 191/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5149 - accuracy: 0.7751 - val_loss: 0.4903 - val_accuracy: 0.7973\n",
      "Epoch 192/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5147 - accuracy: 0.7745 - val_loss: 0.4891 - val_accuracy: 0.7985\n",
      "Epoch 193/500\n",
      "3233/3233 [==============================] - 0s 88us/step - loss: 0.5169 - accuracy: 0.7739 - val_loss: 0.4900 - val_accuracy: 0.7985\n",
      "Epoch 194/500\n",
      "3233/3233 [==============================] - 0s 78us/step - loss: 0.5140 - accuracy: 0.7733 - val_loss: 0.4891 - val_accuracy: 0.8022\n",
      "Epoch 195/500\n",
      "3233/3233 [==============================] - 0s 73us/step - loss: 0.5161 - accuracy: 0.7751 - val_loss: 0.4905 - val_accuracy: 0.8035\n",
      "Epoch 196/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5185 - accuracy: 0.7767 - val_loss: 0.4879 - val_accuracy: 0.8022\n",
      "Epoch 197/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5143 - accuracy: 0.7767 - val_loss: 0.4875 - val_accuracy: 0.7973\n",
      "Epoch 198/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5160 - accuracy: 0.7751 - val_loss: 0.4859 - val_accuracy: 0.8010\n",
      "Epoch 199/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5169 - accuracy: 0.7720 - val_loss: 0.4867 - val_accuracy: 0.7998\n",
      "Epoch 200/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5148 - accuracy: 0.7739 - val_loss: 0.4990 - val_accuracy: 0.7973\n",
      "Epoch 201/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5132 - accuracy: 0.7730 - val_loss: 0.4896 - val_accuracy: 0.8035\n",
      "Epoch 202/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5156 - accuracy: 0.7720 - val_loss: 0.4916 - val_accuracy: 0.7973\n",
      "Epoch 203/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5192 - accuracy: 0.7730 - val_loss: 0.4941 - val_accuracy: 0.7985\n",
      "Epoch 204/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5116 - accuracy: 0.7745 - val_loss: 0.4907 - val_accuracy: 0.7973\n",
      "Epoch 205/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5149 - accuracy: 0.7723 - val_loss: 0.4896 - val_accuracy: 0.7985\n",
      "Epoch 206/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5114 - accuracy: 0.7745 - val_loss: 0.4893 - val_accuracy: 0.8010\n",
      "Epoch 207/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5149 - accuracy: 0.7754 - val_loss: 0.4882 - val_accuracy: 0.7985\n",
      "Epoch 208/500\n",
      "3233/3233 [==============================] - 0s 77us/step - loss: 0.5144 - accuracy: 0.7751 - val_loss: 0.4860 - val_accuracy: 0.7985\n",
      "Epoch 209/500\n",
      "3233/3233 [==============================] - 0s 101us/step - loss: 0.5157 - accuracy: 0.7730 - val_loss: 0.4913 - val_accuracy: 0.7985\n",
      "Epoch 210/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5165 - accuracy: 0.7776 - val_loss: 0.4881 - val_accuracy: 0.7998\n",
      "Epoch 211/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5122 - accuracy: 0.7758 - val_loss: 0.4902 - val_accuracy: 0.7985\n",
      "Epoch 212/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5188 - accuracy: 0.7727 - val_loss: 0.4862 - val_accuracy: 0.7998\n",
      "Epoch 213/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5133 - accuracy: 0.7727 - val_loss: 0.4872 - val_accuracy: 0.8035\n",
      "Epoch 214/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5132 - accuracy: 0.7717 - val_loss: 0.4938 - val_accuracy: 0.7936\n",
      "Epoch 215/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5157 - accuracy: 0.7727 - val_loss: 0.4905 - val_accuracy: 0.7998\n",
      "Epoch 216/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5178 - accuracy: 0.7730 - val_loss: 0.4869 - val_accuracy: 0.8047\n",
      "Epoch 217/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5174 - accuracy: 0.7748 - val_loss: 0.4867 - val_accuracy: 0.7998\n",
      "Epoch 218/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5159 - accuracy: 0.7733 - val_loss: 0.4881 - val_accuracy: 0.8035\n",
      "Epoch 219/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5156 - accuracy: 0.7785 - val_loss: 0.4893 - val_accuracy: 0.8022\n",
      "Epoch 220/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5138 - accuracy: 0.7745 - val_loss: 0.4879 - val_accuracy: 0.8035\n",
      "Epoch 221/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5132 - accuracy: 0.7758 - val_loss: 0.4870 - val_accuracy: 0.7973\n",
      "Epoch 222/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5137 - accuracy: 0.7773 - val_loss: 0.5082 - val_accuracy: 0.7726\n",
      "Epoch 223/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5157 - accuracy: 0.7751 - val_loss: 0.4898 - val_accuracy: 0.7985\n",
      "Epoch 224/500\n",
      "3233/3233 [==============================] - 0s 71us/step - loss: 0.5164 - accuracy: 0.7764 - val_loss: 0.4904 - val_accuracy: 0.7998\n",
      "Epoch 225/500\n",
      "3233/3233 [==============================] - 0s 83us/step - loss: 0.5119 - accuracy: 0.7795 - val_loss: 0.4966 - val_accuracy: 0.7973\n",
      "Epoch 226/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5166 - accuracy: 0.7727 - val_loss: 0.4948 - val_accuracy: 0.7960\n",
      "Epoch 227/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5171 - accuracy: 0.7714 - val_loss: 0.4882 - val_accuracy: 0.7985\n",
      "Epoch 228/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5143 - accuracy: 0.7720 - val_loss: 0.4892 - val_accuracy: 0.7998\n",
      "Epoch 229/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5133 - accuracy: 0.7770 - val_loss: 0.4882 - val_accuracy: 0.7998\n",
      "Epoch 230/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5163 - accuracy: 0.7773 - val_loss: 0.4946 - val_accuracy: 0.7985\n",
      "Epoch 231/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5176 - accuracy: 0.7764 - val_loss: 0.4895 - val_accuracy: 0.8010\n",
      "Epoch 232/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5146 - accuracy: 0.7736 - val_loss: 0.4925 - val_accuracy: 0.7973\n",
      "Epoch 233/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5149 - accuracy: 0.7773 - val_loss: 0.4951 - val_accuracy: 0.7960\n",
      "Epoch 234/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5172 - accuracy: 0.7689 - val_loss: 0.4913 - val_accuracy: 0.7973\n",
      "Epoch 235/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5114 - accuracy: 0.7745 - val_loss: 0.4875 - val_accuracy: 0.7985\n",
      "Epoch 236/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5154 - accuracy: 0.7748 - val_loss: 0.4903 - val_accuracy: 0.7948\n",
      "Epoch 237/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5158 - accuracy: 0.7782 - val_loss: 0.4911 - val_accuracy: 0.7960\n",
      "Epoch 238/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5155 - accuracy: 0.7705 - val_loss: 0.4876 - val_accuracy: 0.8010\n",
      "Epoch 239/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5138 - accuracy: 0.7711 - val_loss: 0.4890 - val_accuracy: 0.8010\n",
      "Epoch 240/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5214 - accuracy: 0.7693 - val_loss: 0.4889 - val_accuracy: 0.8022\n",
      "Epoch 241/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5153 - accuracy: 0.7720 - val_loss: 0.4944 - val_accuracy: 0.7948\n",
      "Epoch 242/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5170 - accuracy: 0.7736 - val_loss: 0.4913 - val_accuracy: 0.8035\n",
      "Epoch 243/500\n",
      "3233/3233 [==============================] - 0s 69us/step - loss: 0.5149 - accuracy: 0.7733 - val_loss: 0.4908 - val_accuracy: 0.7985\n",
      "Epoch 244/500\n",
      "3233/3233 [==============================] - 0s 76us/step - loss: 0.5175 - accuracy: 0.7742 - val_loss: 0.4878 - val_accuracy: 0.8022\n",
      "Epoch 245/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5177 - accuracy: 0.7748 - val_loss: 0.4912 - val_accuracy: 0.7973\n",
      "Epoch 246/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5168 - accuracy: 0.7717 - val_loss: 0.4886 - val_accuracy: 0.7998\n",
      "Epoch 247/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5163 - accuracy: 0.7767 - val_loss: 0.4897 - val_accuracy: 0.8047\n",
      "Epoch 248/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5152 - accuracy: 0.7711 - val_loss: 0.4899 - val_accuracy: 0.7960\n",
      "Epoch 249/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5168 - accuracy: 0.7736 - val_loss: 0.4859 - val_accuracy: 0.8022\n",
      "Epoch 250/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5185 - accuracy: 0.7770 - val_loss: 0.4866 - val_accuracy: 0.7998\n",
      "Epoch 251/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5164 - accuracy: 0.7770 - val_loss: 0.4875 - val_accuracy: 0.8022\n",
      "Epoch 252/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5200 - accuracy: 0.7699 - val_loss: 0.4857 - val_accuracy: 0.8047\n",
      "Epoch 253/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5165 - accuracy: 0.7792 - val_loss: 0.4880 - val_accuracy: 0.7973\n",
      "Epoch 254/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5132 - accuracy: 0.7742 - val_loss: 0.4899 - val_accuracy: 0.7998\n",
      "Epoch 255/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5101 - accuracy: 0.7758 - val_loss: 0.4852 - val_accuracy: 0.7960\n",
      "Epoch 256/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5155 - accuracy: 0.7758 - val_loss: 0.4906 - val_accuracy: 0.7973\n",
      "Epoch 257/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5137 - accuracy: 0.7717 - val_loss: 0.4907 - val_accuracy: 0.7973\n",
      "Epoch 258/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5163 - accuracy: 0.7739 - val_loss: 0.4897 - val_accuracy: 0.8010\n",
      "Epoch 259/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5185 - accuracy: 0.7748 - val_loss: 0.4869 - val_accuracy: 0.8035\n",
      "Epoch 260/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5113 - accuracy: 0.7788 - val_loss: 0.4899 - val_accuracy: 0.8010\n",
      "Epoch 261/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5159 - accuracy: 0.7736 - val_loss: 0.4916 - val_accuracy: 0.7960\n",
      "Epoch 262/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5133 - accuracy: 0.7727 - val_loss: 0.4856 - val_accuracy: 0.7985\n",
      "Epoch 263/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5114 - accuracy: 0.7736 - val_loss: 0.4861 - val_accuracy: 0.7998\n",
      "Epoch 264/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5136 - accuracy: 0.7745 - val_loss: 0.4874 - val_accuracy: 0.7960\n",
      "Epoch 265/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5142 - accuracy: 0.7702 - val_loss: 0.4875 - val_accuracy: 0.7985\n",
      "Epoch 266/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5150 - accuracy: 0.7779 - val_loss: 0.4923 - val_accuracy: 0.8035\n",
      "Epoch 267/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5122 - accuracy: 0.7761 - val_loss: 0.4937 - val_accuracy: 0.7998\n",
      "Epoch 268/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5147 - accuracy: 0.7696 - val_loss: 0.4961 - val_accuracy: 0.7985\n",
      "Epoch 269/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5158 - accuracy: 0.7699 - val_loss: 0.4904 - val_accuracy: 0.7960\n",
      "Epoch 270/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5088 - accuracy: 0.7764 - val_loss: 0.4900 - val_accuracy: 0.7985\n",
      "Epoch 271/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5166 - accuracy: 0.7751 - val_loss: 0.4929 - val_accuracy: 0.7948\n",
      "Epoch 272/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5155 - accuracy: 0.7748 - val_loss: 0.4991 - val_accuracy: 0.7899\n",
      "Epoch 273/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5180 - accuracy: 0.7754 - val_loss: 0.4927 - val_accuracy: 0.7960\n",
      "Epoch 274/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5169 - accuracy: 0.7761 - val_loss: 0.4855 - val_accuracy: 0.8035\n",
      "Epoch 275/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5128 - accuracy: 0.7751 - val_loss: 0.4861 - val_accuracy: 0.8010\n",
      "Epoch 276/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5140 - accuracy: 0.7788 - val_loss: 0.4869 - val_accuracy: 0.8047\n",
      "Epoch 277/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5132 - accuracy: 0.7736 - val_loss: 0.4873 - val_accuracy: 0.7985\n",
      "Epoch 278/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5152 - accuracy: 0.7761 - val_loss: 0.4871 - val_accuracy: 0.8047\n",
      "Epoch 279/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5143 - accuracy: 0.7739 - val_loss: 0.4915 - val_accuracy: 0.7998\n",
      "Epoch 280/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5167 - accuracy: 0.7745 - val_loss: 0.4882 - val_accuracy: 0.8010\n",
      "Epoch 281/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5088 - accuracy: 0.7742 - val_loss: 0.4861 - val_accuracy: 0.7973\n",
      "Epoch 282/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5146 - accuracy: 0.7739 - val_loss: 0.4903 - val_accuracy: 0.7985\n",
      "Epoch 283/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5156 - accuracy: 0.7730 - val_loss: 0.4906 - val_accuracy: 0.7985\n",
      "Epoch 284/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5145 - accuracy: 0.7733 - val_loss: 0.4859 - val_accuracy: 0.7998\n",
      "Epoch 285/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5153 - accuracy: 0.7742 - val_loss: 0.4879 - val_accuracy: 0.7973\n",
      "Epoch 286/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5137 - accuracy: 0.7779 - val_loss: 0.4872 - val_accuracy: 0.8022\n",
      "Epoch 287/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5114 - accuracy: 0.7739 - val_loss: 0.4853 - val_accuracy: 0.7973\n",
      "Epoch 288/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5112 - accuracy: 0.7705 - val_loss: 0.4912 - val_accuracy: 0.7948\n",
      "Epoch 289/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5084 - accuracy: 0.7761 - val_loss: 0.4884 - val_accuracy: 0.7985\n",
      "Epoch 290/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5108 - accuracy: 0.7758 - val_loss: 0.4862 - val_accuracy: 0.8022\n",
      "Epoch 291/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5153 - accuracy: 0.7736 - val_loss: 0.4883 - val_accuracy: 0.7973\n",
      "Epoch 292/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5132 - accuracy: 0.7764 - val_loss: 0.4853 - val_accuracy: 0.8022\n",
      "Epoch 293/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5098 - accuracy: 0.7748 - val_loss: 0.4858 - val_accuracy: 0.7973\n",
      "Epoch 294/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5172 - accuracy: 0.7748 - val_loss: 0.4908 - val_accuracy: 0.7998\n",
      "Epoch 295/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5105 - accuracy: 0.7761 - val_loss: 0.4903 - val_accuracy: 0.7973\n",
      "Epoch 296/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5205 - accuracy: 0.7699 - val_loss: 0.4960 - val_accuracy: 0.7948\n",
      "Epoch 297/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5166 - accuracy: 0.7739 - val_loss: 0.4866 - val_accuracy: 0.8010\n",
      "Epoch 298/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5144 - accuracy: 0.7761 - val_loss: 0.4942 - val_accuracy: 0.7960\n",
      "Epoch 299/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5156 - accuracy: 0.7727 - val_loss: 0.4860 - val_accuracy: 0.7973\n",
      "Epoch 300/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5116 - accuracy: 0.7711 - val_loss: 0.4883 - val_accuracy: 0.8022\n",
      "Epoch 301/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5117 - accuracy: 0.7761 - val_loss: 0.4865 - val_accuracy: 0.7985\n",
      "Epoch 302/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5115 - accuracy: 0.7779 - val_loss: 0.4906 - val_accuracy: 0.7948\n",
      "Epoch 303/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5128 - accuracy: 0.7779 - val_loss: 0.4861 - val_accuracy: 0.7985\n",
      "Epoch 304/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5142 - accuracy: 0.7730 - val_loss: 0.4872 - val_accuracy: 0.8022\n",
      "Epoch 305/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5179 - accuracy: 0.7714 - val_loss: 0.4859 - val_accuracy: 0.7998\n",
      "Epoch 306/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5149 - accuracy: 0.7758 - val_loss: 0.4866 - val_accuracy: 0.7998\n",
      "Epoch 307/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5125 - accuracy: 0.7751 - val_loss: 0.4860 - val_accuracy: 0.7998\n",
      "Epoch 308/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5161 - accuracy: 0.7665 - val_loss: 0.4855 - val_accuracy: 0.8010\n",
      "Epoch 309/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5151 - accuracy: 0.7745 - val_loss: 0.4863 - val_accuracy: 0.7985\n",
      "Epoch 310/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5096 - accuracy: 0.7770 - val_loss: 0.4876 - val_accuracy: 0.8022\n",
      "Epoch 311/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5116 - accuracy: 0.7770 - val_loss: 0.4883 - val_accuracy: 0.7985\n",
      "Epoch 312/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5156 - accuracy: 0.7730 - val_loss: 0.4856 - val_accuracy: 0.7998\n",
      "Epoch 313/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5143 - accuracy: 0.7754 - val_loss: 0.4890 - val_accuracy: 0.7973\n",
      "Epoch 314/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5169 - accuracy: 0.7754 - val_loss: 0.4883 - val_accuracy: 0.7948\n",
      "Epoch 315/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5150 - accuracy: 0.7751 - val_loss: 0.4857 - val_accuracy: 0.8010\n",
      "Epoch 316/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5117 - accuracy: 0.7770 - val_loss: 0.4857 - val_accuracy: 0.8010\n",
      "Epoch 317/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5126 - accuracy: 0.7761 - val_loss: 0.4877 - val_accuracy: 0.8010\n",
      "Epoch 318/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5140 - accuracy: 0.7720 - val_loss: 0.4899 - val_accuracy: 0.7998\n",
      "Epoch 319/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5136 - accuracy: 0.7782 - val_loss: 0.4941 - val_accuracy: 0.7960\n",
      "Epoch 320/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5174 - accuracy: 0.7723 - val_loss: 0.4907 - val_accuracy: 0.7985\n",
      "Epoch 321/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5109 - accuracy: 0.7782 - val_loss: 0.4874 - val_accuracy: 0.8022\n",
      "Epoch 322/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5121 - accuracy: 0.7727 - val_loss: 0.4921 - val_accuracy: 0.7985\n",
      "Epoch 323/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5161 - accuracy: 0.7720 - val_loss: 0.4989 - val_accuracy: 0.7960\n",
      "Epoch 324/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5178 - accuracy: 0.7727 - val_loss: 0.4955 - val_accuracy: 0.7948\n",
      "Epoch 325/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5151 - accuracy: 0.7767 - val_loss: 0.4865 - val_accuracy: 0.8035\n",
      "Epoch 326/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5119 - accuracy: 0.7782 - val_loss: 0.4861 - val_accuracy: 0.8047\n",
      "Epoch 327/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5150 - accuracy: 0.7733 - val_loss: 0.4901 - val_accuracy: 0.8010\n",
      "Epoch 328/500\n",
      "3233/3233 [==============================] - 0s 70us/step - loss: 0.5140 - accuracy: 0.7739 - val_loss: 0.4889 - val_accuracy: 0.8010\n",
      "Epoch 329/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5124 - accuracy: 0.7770 - val_loss: 0.4878 - val_accuracy: 0.7985\n",
      "Epoch 330/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5135 - accuracy: 0.7770 - val_loss: 0.4873 - val_accuracy: 0.8010\n",
      "Epoch 331/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5120 - accuracy: 0.7807 - val_loss: 0.4865 - val_accuracy: 0.7998\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5160 - accuracy: 0.7751 - val_loss: 0.4889 - val_accuracy: 0.7948\n",
      "Epoch 333/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5102 - accuracy: 0.7733 - val_loss: 0.4927 - val_accuracy: 0.7973\n",
      "Epoch 334/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5154 - accuracy: 0.7751 - val_loss: 0.4888 - val_accuracy: 0.7948\n",
      "Epoch 335/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5168 - accuracy: 0.7751 - val_loss: 0.4910 - val_accuracy: 0.7973\n",
      "Epoch 336/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5155 - accuracy: 0.7739 - val_loss: 0.4871 - val_accuracy: 0.7985\n",
      "Epoch 337/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5140 - accuracy: 0.7788 - val_loss: 0.4852 - val_accuracy: 0.8010\n",
      "Epoch 338/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5135 - accuracy: 0.7720 - val_loss: 0.4883 - val_accuracy: 0.7973\n",
      "Epoch 339/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5137 - accuracy: 0.7748 - val_loss: 0.4910 - val_accuracy: 0.7985\n",
      "Epoch 340/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5179 - accuracy: 0.7751 - val_loss: 0.4880 - val_accuracy: 0.7973\n",
      "Epoch 341/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5166 - accuracy: 0.7739 - val_loss: 0.5018 - val_accuracy: 0.7923\n",
      "Epoch 342/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5165 - accuracy: 0.7739 - val_loss: 0.4907 - val_accuracy: 0.7948\n",
      "Epoch 343/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5095 - accuracy: 0.7767 - val_loss: 0.4858 - val_accuracy: 0.8022\n",
      "Epoch 344/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5137 - accuracy: 0.7711 - val_loss: 0.4990 - val_accuracy: 0.7936\n",
      "Epoch 345/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5131 - accuracy: 0.7745 - val_loss: 0.4888 - val_accuracy: 0.7998\n",
      "Epoch 346/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5114 - accuracy: 0.7798 - val_loss: 0.4852 - val_accuracy: 0.8022\n",
      "Epoch 347/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5088 - accuracy: 0.7761 - val_loss: 0.4904 - val_accuracy: 0.7985\n",
      "Epoch 348/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5184 - accuracy: 0.7717 - val_loss: 0.4893 - val_accuracy: 0.7985\n",
      "Epoch 349/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5163 - accuracy: 0.7736 - val_loss: 0.4886 - val_accuracy: 0.7973\n",
      "Epoch 350/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5108 - accuracy: 0.7745 - val_loss: 0.4873 - val_accuracy: 0.7960\n",
      "Epoch 351/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5163 - accuracy: 0.7736 - val_loss: 0.4966 - val_accuracy: 0.7948\n",
      "Epoch 352/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5104 - accuracy: 0.7733 - val_loss: 0.4861 - val_accuracy: 0.8010\n",
      "Epoch 353/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5153 - accuracy: 0.7758 - val_loss: 0.4867 - val_accuracy: 0.8010\n",
      "Epoch 354/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5099 - accuracy: 0.7810 - val_loss: 0.4910 - val_accuracy: 0.7985\n",
      "Epoch 355/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5118 - accuracy: 0.7779 - val_loss: 0.4876 - val_accuracy: 0.7973\n",
      "Epoch 356/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5137 - accuracy: 0.7745 - val_loss: 0.5044 - val_accuracy: 0.7874\n",
      "Epoch 357/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5127 - accuracy: 0.7733 - val_loss: 0.4848 - val_accuracy: 0.7998\n",
      "Epoch 358/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5131 - accuracy: 0.7748 - val_loss: 0.4989 - val_accuracy: 0.7948\n",
      "Epoch 359/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5131 - accuracy: 0.7770 - val_loss: 0.4913 - val_accuracy: 0.7998\n",
      "Epoch 360/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5160 - accuracy: 0.7720 - val_loss: 0.4891 - val_accuracy: 0.7998\n",
      "Epoch 361/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5156 - accuracy: 0.7711 - val_loss: 0.4887 - val_accuracy: 0.7973\n",
      "Epoch 362/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5121 - accuracy: 0.7720 - val_loss: 0.4868 - val_accuracy: 0.8022\n",
      "Epoch 363/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5115 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7998\n",
      "Epoch 364/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5137 - accuracy: 0.7742 - val_loss: 0.4851 - val_accuracy: 0.8022\n",
      "Epoch 365/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5169 - accuracy: 0.7711 - val_loss: 0.4889 - val_accuracy: 0.7998\n",
      "Epoch 366/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5163 - accuracy: 0.7733 - val_loss: 0.4875 - val_accuracy: 0.7998\n",
      "Epoch 367/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5165 - accuracy: 0.7727 - val_loss: 0.4873 - val_accuracy: 0.8022\n",
      "Epoch 368/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5158 - accuracy: 0.7745 - val_loss: 0.4878 - val_accuracy: 0.8022\n",
      "Epoch 369/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5159 - accuracy: 0.7754 - val_loss: 0.4871 - val_accuracy: 0.8022\n",
      "Epoch 370/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5134 - accuracy: 0.7748 - val_loss: 0.5012 - val_accuracy: 0.7936\n",
      "Epoch 371/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5134 - accuracy: 0.7720 - val_loss: 0.4902 - val_accuracy: 0.7985\n",
      "Epoch 372/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5138 - accuracy: 0.7727 - val_loss: 0.4926 - val_accuracy: 0.7985\n",
      "Epoch 373/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5158 - accuracy: 0.7748 - val_loss: 0.4888 - val_accuracy: 0.7985\n",
      "Epoch 374/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5155 - accuracy: 0.7720 - val_loss: 0.4885 - val_accuracy: 0.8010\n",
      "Epoch 375/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5117 - accuracy: 0.7764 - val_loss: 0.4884 - val_accuracy: 0.7948\n",
      "Epoch 376/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5133 - accuracy: 0.7742 - val_loss: 0.4868 - val_accuracy: 0.7998\n",
      "Epoch 377/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5143 - accuracy: 0.7714 - val_loss: 0.4937 - val_accuracy: 0.7911\n",
      "Epoch 378/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5093 - accuracy: 0.7736 - val_loss: 0.4876 - val_accuracy: 0.7985\n",
      "Epoch 379/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5120 - accuracy: 0.7770 - val_loss: 0.4890 - val_accuracy: 0.7936\n",
      "Epoch 380/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5144 - accuracy: 0.7696 - val_loss: 0.4848 - val_accuracy: 0.7973\n",
      "Epoch 381/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5156 - accuracy: 0.7733 - val_loss: 0.4859 - val_accuracy: 0.7998\n",
      "Epoch 382/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5109 - accuracy: 0.7758 - val_loss: 0.4864 - val_accuracy: 0.7985\n",
      "Epoch 383/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5089 - accuracy: 0.7826 - val_loss: 0.4886 - val_accuracy: 0.7985\n",
      "Epoch 384/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5106 - accuracy: 0.7792 - val_loss: 0.4861 - val_accuracy: 0.8010\n",
      "Epoch 385/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5145 - accuracy: 0.7680 - val_loss: 0.4888 - val_accuracy: 0.7973\n",
      "Epoch 386/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5223 - accuracy: 0.7714 - val_loss: 0.4866 - val_accuracy: 0.8010\n",
      "Epoch 387/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5082 - accuracy: 0.7733 - val_loss: 0.4845 - val_accuracy: 0.8010\n",
      "Epoch 388/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5082 - accuracy: 0.7739 - val_loss: 0.4869 - val_accuracy: 0.7985\n",
      "Epoch 389/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5149 - accuracy: 0.7742 - val_loss: 0.4936 - val_accuracy: 0.7960\n",
      "Epoch 390/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5137 - accuracy: 0.7742 - val_loss: 0.4898 - val_accuracy: 0.7998\n",
      "Epoch 391/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5152 - accuracy: 0.7742 - val_loss: 0.4921 - val_accuracy: 0.7985\n",
      "Epoch 392/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5163 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7960\n",
      "Epoch 393/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5137 - accuracy: 0.7708 - val_loss: 0.4855 - val_accuracy: 0.7998\n",
      "Epoch 394/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5119 - accuracy: 0.7779 - val_loss: 0.4848 - val_accuracy: 0.8022\n",
      "Epoch 395/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5126 - accuracy: 0.7736 - val_loss: 0.4848 - val_accuracy: 0.8010\n",
      "Epoch 396/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5110 - accuracy: 0.7785 - val_loss: 0.5087 - val_accuracy: 0.7899\n",
      "Epoch 397/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5122 - accuracy: 0.7748 - val_loss: 0.4870 - val_accuracy: 0.7973\n",
      "Epoch 398/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5152 - accuracy: 0.7758 - val_loss: 0.4867 - val_accuracy: 0.7973\n",
      "Epoch 399/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5180 - accuracy: 0.7720 - val_loss: 0.4876 - val_accuracy: 0.7998\n",
      "Epoch 400/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5196 - accuracy: 0.7683 - val_loss: 0.4897 - val_accuracy: 0.7973\n",
      "Epoch 401/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5167 - accuracy: 0.7730 - val_loss: 0.4914 - val_accuracy: 0.8035\n",
      "Epoch 402/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5158 - accuracy: 0.7761 - val_loss: 0.4944 - val_accuracy: 0.7973\n",
      "Epoch 403/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5132 - accuracy: 0.7733 - val_loss: 0.4884 - val_accuracy: 0.7960\n",
      "Epoch 404/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5174 - accuracy: 0.7727 - val_loss: 0.4908 - val_accuracy: 0.7985\n",
      "Epoch 405/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5137 - accuracy: 0.7754 - val_loss: 0.4857 - val_accuracy: 0.8022\n",
      "Epoch 406/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5096 - accuracy: 0.7745 - val_loss: 0.4959 - val_accuracy: 0.7960\n",
      "Epoch 407/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5179 - accuracy: 0.7727 - val_loss: 0.4863 - val_accuracy: 0.7998\n",
      "Epoch 408/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5112 - accuracy: 0.7754 - val_loss: 0.4950 - val_accuracy: 0.7936\n",
      "Epoch 409/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5096 - accuracy: 0.7730 - val_loss: 0.4880 - val_accuracy: 0.7973\n",
      "Epoch 410/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5159 - accuracy: 0.7758 - val_loss: 0.4861 - val_accuracy: 0.7960\n",
      "Epoch 411/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5144 - accuracy: 0.7751 - val_loss: 0.4893 - val_accuracy: 0.7960\n",
      "Epoch 412/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5168 - accuracy: 0.7723 - val_loss: 0.4871 - val_accuracy: 0.7948\n",
      "Epoch 413/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5118 - accuracy: 0.7758 - val_loss: 0.4887 - val_accuracy: 0.7985\n",
      "Epoch 414/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5182 - accuracy: 0.7723 - val_loss: 0.4875 - val_accuracy: 0.8022\n",
      "Epoch 415/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5119 - accuracy: 0.7779 - val_loss: 0.4877 - val_accuracy: 0.7973\n",
      "Epoch 416/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5118 - accuracy: 0.7736 - val_loss: 0.4932 - val_accuracy: 0.7911\n",
      "Epoch 417/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5134 - accuracy: 0.7733 - val_loss: 0.4870 - val_accuracy: 0.7998\n",
      "Epoch 418/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5091 - accuracy: 0.7779 - val_loss: 0.4854 - val_accuracy: 0.7998\n",
      "Epoch 419/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5070 - accuracy: 0.7758 - val_loss: 0.4848 - val_accuracy: 0.7985\n",
      "Epoch 420/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5078 - accuracy: 0.7801 - val_loss: 0.4879 - val_accuracy: 0.8010\n",
      "Epoch 421/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5120 - accuracy: 0.7680 - val_loss: 0.4903 - val_accuracy: 0.8022\n",
      "Epoch 422/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5110 - accuracy: 0.7739 - val_loss: 0.4868 - val_accuracy: 0.7998\n",
      "Epoch 423/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5095 - accuracy: 0.7742 - val_loss: 0.4916 - val_accuracy: 0.7923\n",
      "Epoch 424/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5125 - accuracy: 0.7730 - val_loss: 0.4875 - val_accuracy: 0.7985\n",
      "Epoch 425/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5138 - accuracy: 0.7764 - val_loss: 0.4904 - val_accuracy: 0.7985\n",
      "Epoch 426/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5123 - accuracy: 0.7742 - val_loss: 0.4868 - val_accuracy: 0.7973\n",
      "Epoch 427/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5152 - accuracy: 0.7801 - val_loss: 0.4891 - val_accuracy: 0.7936\n",
      "Epoch 428/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5141 - accuracy: 0.7742 - val_loss: 0.4938 - val_accuracy: 0.7936\n",
      "Epoch 429/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5126 - accuracy: 0.7717 - val_loss: 0.4844 - val_accuracy: 0.8010\n",
      "Epoch 430/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5187 - accuracy: 0.7717 - val_loss: 0.4873 - val_accuracy: 0.7998\n",
      "Epoch 431/500\n",
      "3233/3233 [==============================] - 0s 66us/step - loss: 0.5101 - accuracy: 0.7745 - val_loss: 0.4930 - val_accuracy: 0.7973\n",
      "Epoch 432/500\n",
      "3233/3233 [==============================] - 0s 65us/step - loss: 0.5161 - accuracy: 0.7736 - val_loss: 0.4892 - val_accuracy: 0.7985\n",
      "Epoch 433/500\n",
      "3233/3233 [==============================] - 0s 62us/step - loss: 0.5095 - accuracy: 0.7773 - val_loss: 0.4865 - val_accuracy: 0.7948\n",
      "Epoch 434/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5104 - accuracy: 0.7696 - val_loss: 0.4877 - val_accuracy: 0.7973\n",
      "Epoch 435/500\n",
      "3233/3233 [==============================] - 0s 67us/step - loss: 0.5144 - accuracy: 0.7764 - val_loss: 0.4872 - val_accuracy: 0.7998\n",
      "Epoch 436/500\n",
      "3233/3233 [==============================] - 0s 64us/step - loss: 0.5164 - accuracy: 0.7748 - val_loss: 0.4865 - val_accuracy: 0.7936\n",
      "Epoch 437/500\n",
      "3233/3233 [==============================] - 0s 63us/step - loss: 0.5127 - accuracy: 0.7748 - val_loss: 0.4900 - val_accuracy: 0.7985\n",
      "Epoch 438/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5127 - accuracy: 0.7785 - val_loss: 0.4863 - val_accuracy: 0.7985\n",
      "Epoch 439/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5159 - accuracy: 0.7720 - val_loss: 0.4879 - val_accuracy: 0.7985\n",
      "Epoch 440/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5156 - accuracy: 0.7767 - val_loss: 0.4879 - val_accuracy: 0.8010\n",
      "Epoch 441/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5162 - accuracy: 0.7779 - val_loss: 0.4934 - val_accuracy: 0.7948\n",
      "Epoch 442/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5172 - accuracy: 0.7739 - val_loss: 0.4863 - val_accuracy: 0.7973\n",
      "Epoch 443/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5142 - accuracy: 0.7733 - val_loss: 0.4872 - val_accuracy: 0.7973\n",
      "Epoch 444/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5130 - accuracy: 0.7754 - val_loss: 0.4890 - val_accuracy: 0.7973\n",
      "Epoch 445/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5103 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7973\n",
      "Epoch 446/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5130 - accuracy: 0.7711 - val_loss: 0.4959 - val_accuracy: 0.7960\n",
      "Epoch 447/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5150 - accuracy: 0.7742 - val_loss: 0.4874 - val_accuracy: 0.7948\n",
      "Epoch 448/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5153 - accuracy: 0.7782 - val_loss: 0.4872 - val_accuracy: 0.7985\n",
      "Epoch 449/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5145 - accuracy: 0.7782 - val_loss: 0.4865 - val_accuracy: 0.7973\n",
      "Epoch 450/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5103 - accuracy: 0.7767 - val_loss: 0.4918 - val_accuracy: 0.7985\n",
      "Epoch 451/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5120 - accuracy: 0.7742 - val_loss: 0.4872 - val_accuracy: 0.7973\n",
      "Epoch 452/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5109 - accuracy: 0.7776 - val_loss: 0.4914 - val_accuracy: 0.7960\n",
      "Epoch 453/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5147 - accuracy: 0.7736 - val_loss: 0.4857 - val_accuracy: 0.7960\n",
      "Epoch 454/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5156 - accuracy: 0.7736 - val_loss: 0.4866 - val_accuracy: 0.8010\n",
      "Epoch 455/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5137 - accuracy: 0.7748 - val_loss: 0.4864 - val_accuracy: 0.7973\n",
      "Epoch 456/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5134 - accuracy: 0.7720 - val_loss: 0.4906 - val_accuracy: 0.7998\n",
      "Epoch 457/500\n",
      "3233/3233 [==============================] - 0s 60us/step - loss: 0.5107 - accuracy: 0.7739 - val_loss: 0.4892 - val_accuracy: 0.8035\n",
      "Epoch 458/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5103 - accuracy: 0.7767 - val_loss: 0.4942 - val_accuracy: 0.7985\n",
      "Epoch 459/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5117 - accuracy: 0.7751 - val_loss: 0.4861 - val_accuracy: 0.7998\n",
      "Epoch 460/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5089 - accuracy: 0.7751 - val_loss: 0.4872 - val_accuracy: 0.7998\n",
      "Epoch 461/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5112 - accuracy: 0.7745 - val_loss: 0.4849 - val_accuracy: 0.7985\n",
      "Epoch 462/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5169 - accuracy: 0.7748 - val_loss: 0.4843 - val_accuracy: 0.7973\n",
      "Epoch 463/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5135 - accuracy: 0.7717 - val_loss: 0.4853 - val_accuracy: 0.7960\n",
      "Epoch 464/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5139 - accuracy: 0.7764 - val_loss: 0.4892 - val_accuracy: 0.7948\n",
      "Epoch 465/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5135 - accuracy: 0.7761 - val_loss: 0.4828 - val_accuracy: 0.7985\n",
      "Epoch 466/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5143 - accuracy: 0.7736 - val_loss: 0.4836 - val_accuracy: 0.8035\n",
      "Epoch 467/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5134 - accuracy: 0.7708 - val_loss: 0.4862 - val_accuracy: 0.7973\n",
      "Epoch 468/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5136 - accuracy: 0.7733 - val_loss: 0.4870 - val_accuracy: 0.7960\n",
      "Epoch 469/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5167 - accuracy: 0.7699 - val_loss: 0.4858 - val_accuracy: 0.7948\n",
      "Epoch 470/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5148 - accuracy: 0.7717 - val_loss: 0.4864 - val_accuracy: 0.7985\n",
      "Epoch 471/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5111 - accuracy: 0.7758 - val_loss: 0.4895 - val_accuracy: 0.7985\n",
      "Epoch 472/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5149 - accuracy: 0.7730 - val_loss: 0.4881 - val_accuracy: 0.7985\n",
      "Epoch 473/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5101 - accuracy: 0.7742 - val_loss: 0.4882 - val_accuracy: 0.7960\n",
      "Epoch 474/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5106 - accuracy: 0.7733 - val_loss: 0.4871 - val_accuracy: 0.8035\n",
      "Epoch 475/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5081 - accuracy: 0.7801 - val_loss: 0.4893 - val_accuracy: 0.7948\n",
      "Epoch 476/500\n",
      "3233/3233 [==============================] - 0s 68us/step - loss: 0.5141 - accuracy: 0.7758 - val_loss: 0.4911 - val_accuracy: 0.7899\n",
      "Epoch 477/500\n",
      "3233/3233 [==============================] - 0s 61us/step - loss: 0.5131 - accuracy: 0.7754 - val_loss: 0.4836 - val_accuracy: 0.7985\n",
      "Epoch 478/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5116 - accuracy: 0.7751 - val_loss: 0.4901 - val_accuracy: 0.7985\n",
      "Epoch 479/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5120 - accuracy: 0.7705 - val_loss: 0.4891 - val_accuracy: 0.8010\n",
      "Epoch 480/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5124 - accuracy: 0.7739 - val_loss: 0.4965 - val_accuracy: 0.7936\n",
      "Epoch 481/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5101 - accuracy: 0.7761 - val_loss: 0.4861 - val_accuracy: 0.7998\n",
      "Epoch 482/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5114 - accuracy: 0.7767 - val_loss: 0.4918 - val_accuracy: 0.7998\n",
      "Epoch 483/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5085 - accuracy: 0.7776 - val_loss: 0.4869 - val_accuracy: 0.7998\n",
      "Epoch 484/500\n",
      "3233/3233 [==============================] - 0s 59us/step - loss: 0.5173 - accuracy: 0.7758 - val_loss: 0.4871 - val_accuracy: 0.7985\n",
      "Epoch 485/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5151 - accuracy: 0.7683 - val_loss: 0.4851 - val_accuracy: 0.7973\n",
      "Epoch 486/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5101 - accuracy: 0.7758 - val_loss: 0.5076 - val_accuracy: 0.7923\n",
      "Epoch 487/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5162 - accuracy: 0.7742 - val_loss: 0.4899 - val_accuracy: 0.7936\n",
      "Epoch 488/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5128 - accuracy: 0.7745 - val_loss: 0.4897 - val_accuracy: 0.7936\n",
      "Epoch 489/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5156 - accuracy: 0.7711 - val_loss: 0.4903 - val_accuracy: 0.8010\n",
      "Epoch 490/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5164 - accuracy: 0.7773 - val_loss: 0.4858 - val_accuracy: 0.7985\n",
      "Epoch 491/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5108 - accuracy: 0.7733 - val_loss: 0.4870 - val_accuracy: 0.7985\n",
      "Epoch 492/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5165 - accuracy: 0.7748 - val_loss: 0.4888 - val_accuracy: 0.7948\n",
      "Epoch 493/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5110 - accuracy: 0.7720 - val_loss: 0.4909 - val_accuracy: 0.7998\n",
      "Epoch 494/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5167 - accuracy: 0.7745 - val_loss: 0.4856 - val_accuracy: 0.8022\n",
      "Epoch 495/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5193 - accuracy: 0.7739 - val_loss: 0.4859 - val_accuracy: 0.7998\n",
      "Epoch 496/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5157 - accuracy: 0.7723 - val_loss: 0.4855 - val_accuracy: 0.7985\n",
      "Epoch 497/500\n",
      "3233/3233 [==============================] - 0s 58us/step - loss: 0.5121 - accuracy: 0.7739 - val_loss: 0.4876 - val_accuracy: 0.7960\n",
      "Epoch 498/500\n",
      "3233/3233 [==============================] - 0s 57us/step - loss: 0.5154 - accuracy: 0.7761 - val_loss: 0.4928 - val_accuracy: 0.7998\n",
      "Epoch 499/500\n",
      "3233/3233 [==============================] - 0s 56us/step - loss: 0.5206 - accuracy: 0.7764 - val_loss: 0.4945 - val_accuracy: 0.7899\n",
      "Epoch 500/500\n",
      "3233/3233 [==============================] - 0s 55us/step - loss: 0.5134 - accuracy: 0.7758 - val_loss: 0.4879 - val_accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "model_output = model.fit(x_train,y_train,epochs=500,batch_size=20,verbose=1,validation_data=(x_test,y_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :  0.7735366\n",
      "Validation Accuracy :  0.7988380751609803\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy : ' , np.mean(model_output.history[\"accuracy\"]))\n",
    "print('Validation Accuracy : ' , np.mean(model_output.history[\"val_accuracy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(model_output.history['accuracy'])\n",
    "plt.plot(model_output.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model_output.history['loss'])\n",
    "plt.plot(model_output.history['val_loss'])\n",
    "plt.title('model_output loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "rounded = [round(x[0]) for x in y_pred]\n",
    "y_pred1 = np.array(rounded,dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-f0003380975d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#ROC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprob_neural\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_rbf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Area under the ROC curve : %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#ROC\n",
    "prob_neural = model.fit(x_train, y_train).predict_proba(x_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_rbf[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[437,  83],\n",
       "       [ 88, 201]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7077464788732394"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Females : 59.22810489856507 %\n",
      "Males : 40.771895101434936 %\n"
     ]
    }
   ],
   "source": [
    "All = data.shape[0]\n",
    "female = data[data['SEX'] == 2]\n",
    "male = data[data['SEX'] == 1]\n",
    "\n",
    "x = len(female)/All\n",
    "y = len(male)/All\n",
    "\n",
    "print('Females :',x*100,'%')\n",
    "print('Males :',y*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEaCAYAAAAG87ApAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAdVElEQVR4nO3de7hcVXn48e8i8ULReosiASqoEYtKsUXQUhWqIFoK2uorVAS8EG1FpWpbL1ioqEWL2NQiGiIVqRXfFq35KUop1vJDBVFLQcQLQpQYDAQQQVQk7v6x9oFhOCc5K5zLnJzv53nmmdlrr733O2f2mXfWWvtSuq5DkqTJ2mK2A5AkzS0mDklSExOHJKmJiUOS1MTEIUlqYuKQJDUxcWjeKaUcW0q5Yoa32ZVSDploeoq39YVSyoqJpqdhe6tKKUdP1/o1ehbOdgCaX0opDwb+AjgQ2AH4BfB94DPAB7quu3r2optR2wA/nkzFPsGc3nVdmeS6/wi4fVMD20AcK4BHd12319CsJwG3TvX2NLpMHJoxpZTtgfOpX2rHAv8L/Bx4FDWRvAF47WzF16KUcu+u627b1OW7rvvRVMYDd8bUdd0NU73uDem67rqZ3J5mn11VmknvB+4NPLHrutO7rruk67rvdF332a7rXgkcNVi5lPLqUsq3Sik/L6V8t5TyllLKwoH5q0opbyulLCul3FBKWVtKOaGUsmCgzn1KKSeXUm4qpdxYSjkZuM9wYKWUg0opF/fbWlVKObGUstXA/C+UUj5USjmulHIN8MOJ3mQpZe9SyiX9ui4ppew9Tp3hrquXl1Iu75e5vpRyXillu1LKXsDpA8t0pZQPbyimCbqmtiilHF9KWVdK+UkpZUUpZcuh93eXZUopR5dSVvWvjwVeBjx9II7DBz6HoweWu38p5YOllOv69/PVUsq+A/N36JePUsr/K6XcWkq5spTy4on+photJg7NiL6L6jnA+7qu+8l4dbqB69/0X1RvAN4E/Ca1JfIK4JihxV4NXAPsAbyGmnwOHZh/PPDHfdlTgJ8CrxqK7XDgZOA9wM593WcCHxjaVgAPBZ4B/P4E73Mx8Gnga8BvA68Hlo1Xd2CZ3+m39bfATsBewEf62V8Cjuxfb9M/BltlG42p93zgIcBTgRcBBwDv2lBcQ04A/gX48kAcH5+g7qnAs4BDgCcCXwQ+XUp57FC946lJcRcggX8qpSxpiEmzpes6Hz6m/QHsDnTA84bKvwTc0j8u68t+jdpnvt9Q3UOBHw9MrwJWDtX5HPCx/vVW1K6wI4bqfBW4Ymg9rxyq87Q+3gf1018AvgNssZH3+XbqmM3CgbL9+3UdMlB2xzTwPOAm4NcnWOch9Hl1qHzcmPryFUPTq4AFA2VLqeNLW423TF92NLBqYHoF8IVx4lgFHN2/fnT/3p4zVOfrwKn96x36Oq8bmL+w3wdeMdv7qo+NP2xxaKZMNLD7QmBXYDn1ix7gccCWwJmllFvGHsAHgQeUUh46sPzFQ+v7IbB1//pR1G6pLw3VOf+OoOq6HgGcOLStz/ZVHj2w3Ne6rvvVRt7nzsBXuq4bHJw+f6LKvXOAK4GrSilnlFKWllIWbWSZlpjoY1o/MP1Farfhoya5ncnauX8+b6j8POrnOuiOz67/e63lzs9OI8zBcc2U7wK/on6xfHKssOuPoiqlDA7ojv2geQH1F/WwwbrDA9TdwPJloGwiY3VfC/zXOPNXD7z+6QbWM6aMs70NXoK667pbSim7AXtSu8heCby7lPKMruu+tpHtTSamieIc9Ktxyu61ieueaHvDf4cNfXYaYX5ImhFdPdLns8CrSykP2Ej1y6hdTI/suu6KcR7rN7L8mCuoX057DpX/7kBca4GrgZ0m2NbPJ7mtwdj3GBygB35vYwt1Xbe+67rzuq77a+B3qOM2f9LPvg1gaJ2tnjS0/FP69X6vn74WWDy0zG8PTd8GbCyGy/rnpw2VP3VgnuY4WxyaSX9G7SL5n37w+2Jqv/ZO1HGA9XDHL/B3Au8spUDtylkIPIF6RNZfTWZjXdf9tJTyAeDtpZS1wLepRwY9lvpFOeYtwIdKKT8G/h34JXVA/tld172i8T2eDLwOWF5KOYH6ZfyODS1QSjkQeCS1O+c6auLYHvhmX+Wq/vmAUsr5wM+6rrulMa6HACeVUpb12zoOOKXrurEWy38CJ5dSgjoe8Xzql/3guSZXAS8opTyO2q10c9d1vxjcSNd13yul/Cvw/lLKK6jjPX8KPJ47E6HmOFscmjFd1/2AepTNv1KPlrqQ+iv0PdSjdZ4xUPc44M+Bl1PP9zi/n17VuNk3UpPB6cBXgAcCJw3FdTr16KQ/6OtcRD3PZMJDbifSdd0PgT+kHgxwMfWIqtdtZLEb+2U+R+2aezd1kP3Ufp0X9ev5APUL+x9b4wL+DbiZ+nc8AzgL+MuB+adR/y7/SD14YHvgH4bW8SHq3+ZL1AR38ATbejlwNvDP1M9uT2D/ruu+tQlxawSVrvMOgJKkybPFIUlqYuKQJDWZkcHxiNieeibsw6mH/S3PzGURcSxwBLW/FODNmXlWv8ybqAOZ64HXZObZffl+1P7eBcCKzDx+Jt6DJKmakTGOiNgG2CYzvx4R96dejuG51AHJWzLzhKH6OwMfow4wLqYe8fGYfvZ3gH2ox9dfBBycmd9EkjQjZqTFkZnXUI9LJzNvjojLgW03sMiBwBmZ+Qvgqoi4gppEAK7IzCsBIuKMvu6GEoej/5K0aca94sOMn8cRETtQD8m8kHqY3pERcSj1EMDXZ+aN1KRywcBiq7kz0Vw9VL7Hxra5Zs2aex64AFi0aBHr1q2b7TCkcbl/Tp3Fi4fPB73TjCaOiLgfcCZwVGb+JCJOpp6I1PXP7wFeyvhZbqLLEdytRRERS6kXcSMzWbRospf90cYsXLjQv6dGlvvnzJixxBER96ImjY9m5icAMnPtwPxTqJejhtqS2H5g8e2AsWbDROV3yMzl1IvmAXT+Apk6/qLTKHP/nDqz3uKIiEI96/TyzDxxoHybfvwD6qWlv9G/Xgn8S0ScSB0cX0I9o7cASyJiR+pZvQfhZQwkaUbNVItjT+DFwKURMXYp5TcDB0fErtTuplXUG/WQmZdFRFIHvW8HXpWZ6wEi4kjq5QwWAKdmphdOk6QZNB8uOdI5OD517ArQKHP/nDp9V9W4R1V55rgkqYmJQ5LUxMQhSWpi4pAkNfEOgCNi/REHzHYIk7J241VGwoJTVs52CNJmyxaHJKmJiUOS1MTEIUlqYuKQJDUxcUiSmpg4JElNTBySpCYmDklSExOHJKmJiUOS1MTEIUlqYuKQJDUxcUiSmpg4JElNTBySpCYmDklSExOHJKmJiUOS1MTEIUlqYuKQJDUxcUiSmpg4JElNTBySpCYmDklSExOHJKmJiUOS1MTEIUlqYuKQJDUxcUiSmpg4JElNFs7ERiJie+AjwMOBXwHLM3NZRDwY+DiwA7AKiMy8MSIKsAx4DnArcHhmfr1f12HA0f2q356Zp83Ee5AkVTPV4rgdeH1m/ibwZOBVEbEz8Ebg3MxcApzbTwM8G1jSP5YCJwP0ieYYYA9gd+CYiHjQDL0HSRIzlDgy85qxFkNm3gxcDmwLHAiMtRhOA57bvz4Q+Ehmdpl5AfDAiNgGeBZwTmbekJk3AucA+83Ee5AkVTPSVTUoInYAnghcCGydmddATS4R8bC+2rbA1QOLre7LJiof3sZSakuFzGTRokVT/C6m3trZDmAzMxc+c029hQsX+tnPgBlNHBFxP+BM4KjM/ElETFS1jFPWbaD8LjJzObB8bP66des2IVrNZX7m89OiRYv87KfI4sWLJ5w3Y0dVRcS9qEnjo5n5ib54bd8FRf98bV++Gth+YPHtgDUbKJckzZAZSRz9UVIfAi7PzBMHZq0EDutfHwZ8aqD80IgoEfFk4Ka+S+tsYN+IeFA/KL5vXyZJmiEz1VW1J/Bi4NKIuLgvezNwPJAR8TLgB8AL+nlnUQ/FvYJ6OO5LADLzhog4Drior/e2zLxhZt6CJAmgdN3dhgg2N92aNaPfm7X+iANmO4TNyoJTVs52CJoFjnFMnX6MY7xxZc8clyS1MXFIkpqYOCRJTUwckqQmJg5JUhMThySpiYlDktTExCFJamLikCQ1MXFIkpqYOCRJTUwckqQmJg5JUhMThySpiYlDktTExCFJamLikCQ1MXFIkpqYOCRJTUwckqQmJg5JUhMThySpiYlDktTExCFJarJwtgOQNPrWH3HAbIcwKWtnO4BJWHDKytkO4R6zxSFJamLikCQ1MXFIkpqYOCRJTUwckqQmk04cEfGaiFg0ncFIkkZfy+G4zwTeGRFfAE4H/j0zfzEtUUmSRtakWxyZeQDwCOCzwFHAjyJiRUQ8bbqCkySNnqYTADPzeuAk4KSI2IXa8nhJRFwNnAIsy8xbpj5MSdKoaD5zPCKeARwCHAh8FXg38APgtdTWyFPHWeZUYH/g2sx8fF92LHAEcF1f7c2ZeVY/703Ay4D1wGsy8+y+fD9gGbAAWJGZx7fGL0m6ZyadOCLiBOAg4CbgI8DRmfnDgfkXADdOsPiHgX/slxv03sw8YWg7O/fbeRywGPjPiHhMP/skYB9gNXBRRKzMzG9O9j1Iku65lhbHfYHnZeZF483MzF9GxG4TzDsvInaY5HYOBM7oB96viogrgN37eVdk5pUAEXFGX9fEIUkzqCVx/C1w62BBRDwI2DIz1wBk5rcat39kRBxK7fJ6fWbeCGwLXDBQZ3VfBnD1UPke4600IpYCS/uYWLRo9I8ingsXZ5tL5sJnPpe4f06dzWHfbEkc/w68lLt2R20HrGCCL/CNOBk4Duj65/f06y/j1O0Y/wiwbrwVZ+ZyYPlYnXXr1m1CeJrL/Mw1qubKvrl48eIJ57Ukjp0y89LBgsy8NCIeuylBZeYdP2Ii4hTg0/3kamD7garbAWv61xOVS5JmSMslR66NiEcPFvTT12/KhiNim4HJ5wHf6F+vBA6KiPtExI7AEuArwEXAkojYMSLuTR1An/sXtpekOaalxXEqcGZEvAW4EngUtYtpxcYWjIiPAXsBiyJiNXAMsFdE7ErtbloFvAIgMy+LiKQOet8OvCoz1/frORI4m3o47qmZeVlD/JKkKdCSOI4HfgmcQO0yupqaNE7c2IKZefA4xR/aQP13AO8Yp/ws4KxJxitJmgaTThyZ+Svg7/qHJGmeajpzPCJ2An4LuN9geWaeOpVBSZJGV8uZ428G/hr4X+56PkdHHf+QJM0DLS2Oo4DdM/OS6QpGkjT6Wg7H/RnQema4JGkz09LieCvwvv6qtne5AkE/cC5JmgdaEseH++eXD5QV6hjHgqkKSJI02loSx47TFoUkac5oOY/j+wARsQWwdWZeM21RSZJGVsvhuA8E3g88n3oG+VYRcQD1SKujpyk+SdKIaTmq6gPUu/89AritL/sy8MKpDkqSNLpaEsczqPf/vob+PhiZeR3wsOkITJI0mloSx03AXW5dFRG/ATjWIUnzSEviWEG9rPrewBYR8RTgNGoXliRpnmg5HPddwM+Bk4B7Ua9P9UFg2TTEJUkaUS2H43bA3/cPSdI81XI47u9PNC8zPz814UiSRl1LV9XwHfseCtwbWA08csoikiSNtJauqrtcciQiFgBHAzdPdVCSpNHVclTVXWTmeup9wf9y6sKRJI26TU4cvX0AL6kuSfNIy+D41fRnjPd+Dbgv8GdTHZQkaXS1DI4fMjT9U+A7mfmTKYxHkjTiWgbH/3s6A5EkzQ0tXVWnc9euqnFl5qH3KCJJ0khrGRz/MfBc6m1iV/fLHtiXf2/gIUnajLWMcTwG+IPM/P9jBRHxe8BbM/NZUx6ZJGkktbQ4ngxcMFR2IfCUqQtHkjTqWhLH/wDvjIgtAfrndwAXT0dgkqTR1JI4Dgf2BG6KiLXUGzv9HnDYNMQlSRpRLYfjrgJ+NyK2BxYD12TmD6YrMEnSaGq65EhEPATYC3h6Zv4gIhZHxHbTEpkkaSRNOnFExNOBbwMvAt7aFy8BTp6GuCRJI6qlxfH3wAszcz/g9r7sQmD3KY9KkjSyWs7j2CEzz+1fj51Bfttk1hERpwL7A9dm5uP7sgcDHwd2AFYBkZk3RkSh3sf8OcCtwOGZ+fV+mcOo9wABeHtmntYQvyRpCrS0OL4ZEcMn+j0TuHQSy34Y2G+o7I3AuZm5BDi3nwZ4NrULbAmwlL4rrE80xwB7UFs5x0TEgxrilyRNgZbE8XrgoxFxGrBlRHyQmhD+YmMLZuZ5wA1DxQcCYy2G06iXMxkr/0hmdpl5AfDAiNgGeBZwTmbekJk3Audw92QkSZpmLYfjXhARu1Avr34qcDWwe2au3sRtb52Z1/TrviYiHtaXb9uve8zqvmyi8ruJiKXU1gqZyaJFizYxxJmzdrYD2MzMhc98LnH/nDqbw745qcTR31/8XOBZmfnu6Q2JMk5Zt4Hyu8nM5cDysTrr1q2botA0V/iZa1TNlX1z8eLFE86bVFdVf3/xHSdbf5LW9l1Q9M/X9uWrge0H6m0HrNlAuSRpBrUcVfU3wMkRcQz1S/yOX/uZuSn3HV9JvVzJ8f3zpwbKj4yIM6gD4Tf1XVlnU6+VNTYgvi/wpk3YriTpHmhJHCv650O5M2mU/vWCDS0YER+jnnG+KCJWU4+OOh7IiHgZ8APgBX31s6iH4l5BPRz3JQCZeUNEHAdc1Nd7W2YOD7hLkqbZZM7BeHhm/ojaVbVJMvPgCWY9Y5y6HfCqCdZzKnVgXpI0SybT4vgO8OuZ+X2AiPhEZv7R9IYlSRpVkxnsHj6aaa9piEOSNEdMJnGMe8irJGl+mkxX1cKI2Js7Wx7D02Tm56cjOEnS6JlM4riWuw5IXz803QGPnMqgJEmja6OJIzN3mIE4JElzxFSeCS5JmgdMHJKkJiYOSVITE4ckqYmJQ5LUxMQhSWpi4pAkNTFxSJKamDgkSU1MHJKkJiYOSVITE4ckqYmJQ5LUxMQhSWpi4pAkNTFxSJKamDgkSU1MHJKkJiYOSVITE4ckqYmJQ5LUxMQhSWpi4pAkNTFxSJKamDgkSU1MHJKkJiYOSVITE4ckqcnC2Q4gIlYBNwPrgdszc7eIeDDwcWAHYBUQmXljRBRgGfAc4Fbg8Mz8+mzELUnz1ai0OPbOzF0zc7d++o3AuZm5BDi3nwZ4NrCkfywFTp7xSCVpnhuVxDHsQOC0/vVpwHMHyj+SmV1mXgA8MCK2mY0AJWm+GoXE0QH/ERFfi4ilfdnWmXkNQP/8sL58W+DqgWVX92WSpBky62McwJ6ZuSYiHgacExHf2kDdMk5ZN1zQJ6ClAJnJokWLpibSabR2tgPYzMyFz3wucf+cOpvDvjnriSMz1/TP10bEJ4HdgbURsU1mXtN3RV3bV18NbD+w+HbAmnHWuRxY3k9269atm7b4NZr8zDWq5sq+uXjx4gnnzWpXVURsFRH3H3sN7At8A1gJHNZXOwz4VP96JXBoRJSIeDJw01iXliRpZsz2GMfWwPkR8b/AV4DPZObngOOBfSLiu8A+/TTAWcCVwBXAKcCfzXzIkjS/la672xDB5qZbs+ZuvVkjZ/0RB8x2CJuVBaesnO0QNivun1NnruybfVfVeOPKs97ikCTNMSYOSVITE4ckqYmJQ5LUxMQhSWpi4pAkNTFxSJKamDgkSU1MHJKkJiYOSVITE4ckqYmJQ5LUxMQhSWpi4pAkNTFxSJKamDgkSU1MHJKkJiYOSVITE4ckqYmJQ5LUxMQhSWpi4pAkNTFxSJKamDgkSU1MHJKkJiYOSVITE4ckqYmJQ5LUxMQhSWpi4pAkNTFxSJKamDgkSU1MHJKkJiYOSVITE4ckqcnC2Q5gU0TEfsAyYAGwIjOPn+WQJGnemHMtjohYAJwEPBvYGTg4Inae3agkaf6Yc4kD2B24IjOvzMzbgDOAA2c5JkmaN+ZiV9W2wNUD06uBPQYrRMRSYClAZrJ48eKZi25Tfearsx2BNDH3Tw2Yi4mjjFPWDU5k5nJg+cyEM79ExFczc7fZjkMaj/vnzJiLXVWrge0HprcD1sxSLJI078zFFsdFwJKI2BH4IXAQ8CezG5IkzR9zrsWRmbcDRwJnA5fXorxsdqOaV+wC1Chz/5wBpeu6jdeSJKk351ockqTZZeKQJDWZi4PjahAR64FLB4qem5mrpmlbhwO7ZeaR07F+zR8R0QH/nJkv7qcXAtcAF2bm/htYbi/gDRuqo3vOxLH5+1lm7jrbQUiNfgo8PiK2zMyfAftQj6LUCDBxzEP99b6OB/YC7gOclJkf7H+t/Q2wFtgV+AS1tfJaYEtqa+V7EfGHwNHAvYHrgRdl5tqhbTwU+ADwG33RUZn5xYh4OvUClVBP3HxaZt48Xe9Vc9pngT8A/g04GPgY8FSAiNgd+Hvqfvkz4CWZ+e3BhSNiK+B9wBOo33XHZuanIuJxwD9R998tgD/OzO/OyDvaTDjGsfnbMiIu7h+f7MteBtyUmU8CngQc0Z8XA/Bb1ETxBODFwGMyc3dgBfDqvs75wJMz84nUa4X95TjbXQa8t9/GH/fLA7wBeFXfCnoq9Z9eGs8ZwEERcV9gF+DCgXnfov7oeCLw18A7x1n+LcDn+31wb+Dv+mTySmBZvw/uRj2pWA1scWz+xuuq2hfYJSKe308/AFgC3AZclJnXAETE94D/6OtcSv3ng3q2/scjYhvqr7arxtnuM4GdI2Js+tcj4v7AF4ETI+KjwCcy039ajSszL4mIHaitjbOGZj8AOC0illBbrvcaZxX7AgdExBv66ftSW8BfBt4SEdtR90FbG41MHPNTAV6dmWcPFvZdVb8YKPrVwPSvuHN/eR9wYmau7Jc5dpxtbAE8pe+fHnR8RHwGeA5wQUQ8MzO/dQ/eizZvK4ETqN2qDxkoPw74r8x8Xp9cvjDOsoXaDfXtofLLI+JCajfY2RHx8sz8/FQHvjmzq2p+Ohv404i4F0BEPKZvwk/WA7hzoPKwCer8B/UMf/pt7No/PyozL83MdwFfBR7bGrzmlVOBt2XmpUPlg/vg4RMsezbw6ogoABHxxP75kcCVmfkP1MS0y1QHvbmzxTE/rQB2AL7e/1NdBzy3YfljgX+NiB8CFwA7jlPnNcBJEXEJdT87j9q3fFRE7A2sB75JHQCVxtV3ZS4bZ9a7qV1VrwMmai0cRx1Av6Tfz1cB+wMvBA6JiF8CPwLeNtVxb+685IgkqYldVZKkJiYOSVITE4ckqYmJQ5LUxMQhSWpi4pBGUEQcHhHnz3Yc0ng8j0NqEBEHAX8OPJ56BdergNOAkzPTY9s1L9jikCYpIl5PPRnt74CHA1tTT2rck3rNrpHQX/1Ymja2OKRJiIgHUM8wPjQzzxyY9T/Ai/o69wHeAQT1cvWfBP48M3/WX9Prn4H3An9FPXP+zZn5T/2yD6Fe6nsv6pVfh68j9ljqNcJ+h3qm/1szM/t5H6ZeZfgRwNOBA4H/nMr3Lw2yxSFNzlOoyeBTG6jzLuAx1HuZPBrYlnrJ7zEPp15jaVvqpe1PiogH9fNOAn4ObAO8tH8Ad9xX4hzgX4CHUa8W+/7+vhJj/oSatO5Pvey9NG1scUiTswhYl5m3jxVExJeAnakJZT/gCGCXzLyhn/9O6pf9m/pFfkm9YN/twFkRcQuwU0RcRL1nyRMy86fANyLiNOBp/XL7A6vGWifUa4ydCTwfuKwv+1RmfrF//fMpfu/SXZg4pMm5HlgUEQvHkkdm/i5ARKymjnf8GvC1gXuQFGBwvOH6wcQD3ArcD3go9X/x6oF53x94/Qhgj4j48UDZQuD0genBZaVpZeKQJufL1HuTHAicOc78ddRxhsdlZuu9sa8Dbge2p45vwJ233IWaFP47M/fZwDo8okszxsQhTUJm/jgi/oY6tlCAz1FbDLsAW1FvdHUK8N6IODIzr42IbYHHD98wa5x1r4+ITwDHRsRLqZe8P4x6GXCAT1NvgPVi6u1UoY6j3JKZl0/l+5Qmw8FxaZIy893A66j3WL8WWAt8kHqU1Jf65yuodzb8CfXIpp0mufojqd1WPwI+TD3Camy7N1Nvg3oQsKav8y7q2Io047wfhySpiS0OSVITE4ckqYmJQ5LUxMQhSWpi4pAkNTFxSJKamDgkSU1MHJKkJv8H904Kk+4S8voAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot the Gender against the Frequency\n",
    "labels = ['Females','Males']\n",
    "classes = pd.value_counts(data['SEX'], sort = True)\n",
    "classes.plot(kind = 'bar', rot=0)\n",
    "plt.title(\"Gender distribution\")\n",
    "plt.xticks(range(2), labels)\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data\n",
    "x_train is the training part of the matrix of features.\n",
    "x_test is the test part of the matrix of features.\n",
    "y_train is the training part of the dependent variable that is associated to X_train here.\n",
    "y_test is the test part of the dependent variable that is associated to X_train here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling \n",
    "\n",
    "\n",
    "This will help to limit the range and standerdise the variables so that they can all be compared on common grounds. If they do not have the same scale, it will cause problems to the machine learning that we will be applying later on( as most machine learning models is based on euclidean distance). This algorithm will also converge faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MARRIAGE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MARRIAGE'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-eca271e3213d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SEX'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SEX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EDUCATION'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EDUCATION'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MARRIAGE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MARRIAGE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AGE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AGE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PAY_2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PAY_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MARRIAGE'"
     ]
    }
   ],
   "source": [
    "data['LIMIT_BAL'] = StandardScaler().fit_transform(data['LIMIT_BAL'].values.reshape(-1,1))\n",
    "data['SEX'] = StandardScaler().fit_transform(data['SEX'].values.reshape(-1,1))\n",
    "data['EDUCATION'] = StandardScaler().fit_transform(data['EDUCATION'].values.reshape(-1,1))\n",
    "data['MARRIAGE'] = StandardScaler().fit_transform(data['MARRIAGE'].values.reshape(-1,1))\n",
    "data['AGE'] = StandardScaler().fit_transform(data['AGE'].values.reshape(-1,1))\n",
    "data['PAY_2'] = StandardScaler().fit_transform(data['PAY_2'].values.reshape(-1,1))\n",
    "data['PAY_3'] = StandardScaler().fit_transform(data['PAY_3'].values.reshape(-1,1))\n",
    "data['PAY_4'] = StandardScaler().fit_transform(data['PAY_4'].values.reshape(-1,1))\n",
    "data['PAY_5'] = StandardScaler().fit_transform(data['PAY_5'].values.reshape(-1,1))\n",
    "data['BILL_AMT1'] = StandardScaler().fit_transform(data['BILL_AMT1'].values.reshape(-1,1))\n",
    "data['BILL_AMT2'] = StandardScaler().fit_transform(data['BILL_AMT2'].values.reshape(-1,1))\n",
    "data['BILL_AMT3'] = StandardScaler().fit_transform(data['BILL_AMT3'].values.reshape(-1,1))\n",
    "data['BILL_AMT4'] = StandardScaler().fit_transform(data['BILL_AMT4'].values.reshape(-1,1))\n",
    "data['BILL_AMT5'] = StandardScaler().fit_transform(data['BILL_AMT5'].values.reshape(-1,1))\n",
    "data['BILL_AMT6'] = StandardScaler().fit_transform(data['BILL_AMT6'].values.reshape(-1,1))\n",
    "data['PAY_AMT1'] = StandardScaler().fit_transform(data['PAY_AMT1'].values.reshape(-1,1))\n",
    "data['PAY_AMT2'] = StandardScaler().fit_transform(data['PAY_AMT2'].values.reshape(-1,1))\n",
    "data['PAY_AMT3'] = StandardScaler().fit_transform(data['PAY_AMT3'].values.reshape(-1,1))\n",
    "data['PAY_AMT4'] = StandardScaler().fit_transform(data['PAY_AMT4'].values.reshape(-1,1))\n",
    "data['PAY_AMT5'] = StandardScaler().fit_transform(data['PAY_AMT5'].values.reshape(-1,1))\n",
    "data['PAY_AMT6'] = StandardScaler().fit_transform(data['PAY_AMT6'].values.reshape(-1,1))\n",
    "data['default payment next month'] = StandardScaler().fit_transform(data['default payment next month'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_distribution = [data['SEX'].values]\n",
    "sns.distplot(gender_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of anomalous feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_features = data.iloc[:,1:29].columns\n",
    "plt.figure(figsize=(12,28*4))\n",
    "gs = matplotlib.gridspec.GridSpec(28, 1)\n",
    "for i, cn in enumerate(data[anomalous_features]):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    sns.distplot(data[cn][data.SEX == 1], bins=50)\n",
    "    sns.distplot(data[cn][data.SEX == 2], bins=50)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title('histogram of feature: ' + str(cn))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"Age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
